{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.dropbox.com/s/0uxn14y26jcui4v/pspnet50_ade20k.h5?dl=1\n",
      "187842560/187839752 [==============================] - 30s 0us/step\n",
      "Downloading data from https://www.dropbox.com/s/c17g94n946tpalb/pspnet101_cityscapes.h5?dl=1\n",
      "264151040/264145248 [==============================] - 37s 0us/step\n",
      "Downloading data from https://www.dropbox.com/s/uvqj2cjo4b9c5wg/pspnet101_voc2012.h5?dl=1\n",
      "264151040/264149344 [==============================] - 43s 0us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0bae661f1753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# load any of the 3 pretrained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m out = model.predict_segmentation(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0minp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"input_image.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mout_fname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"out.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_segmentation\\predict.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(model, inp, out_fname, checkpoints_path, overlay_img, class_names, show_legends, colors, prediction_width, prediction_height)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Image should be h,w,3 \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0moutput_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Pretrained models\n",
    "\n",
    "How to change the weights with TL?\n",
    "'''\n",
    "\n",
    "from keras_segmentation.pretrained import pspnet_50_ADE_20K , pspnet_101_cityscapes, pspnet_101_voc12\n",
    "\n",
    "model = pspnet_50_ADE_20K() # load the pretrained model trained on ADE20k dataset\n",
    "\n",
    "model = pspnet_101_cityscapes() # load the pretrained model trained on Cityscapes dataset\n",
    "\n",
    "model = pspnet_101_voc12() # load the pretrained model trained on Pascal VOC 2012 dataset\n",
    "\n",
    "# load any of the 3 pretrained models\n",
    "\n",
    "out = model.predict_segmentation(\n",
    "    inp=\"input_image.jpg\",\n",
    "    out_fname=\"out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 367/367 [00:06<00:00, 58.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "WARNING:tensorflow:From C:\\Users\\pablo\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_segmentation\\train.py:156: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 80/512 [===>..........................] - ETA: 1:16:37 - loss: 4.0889 - accuracy: 0.0573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c8f40e993001>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m\"dataset1/images_prepped_train/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_annotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dataset1/annotations_prepped_train/\"\u001b[0m\u001b[1;31m#,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#checkpoints_path = \"/checkpoints/vgg_unet_1\" , epochs=5 #created folder checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_segmentation\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         model.fit_generator(train_gen, steps_per_epoch,\n\u001b[0m\u001b[0;32m    157\u001b[0m                             epochs=epochs, callbacks=callbacks)\n\u001b[0;32m    158\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\"#,\n",
    "    #checkpoints_path = \"/checkpoints/vgg_unet_1\" , epochs=5 #created folder checkpoint\n",
    ")\n",
    "\n",
    "out = model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "\n",
    "# evaluating the model \n",
    "print(model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2, os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = (15, 15)\n",
    "\n",
    "#import ochumanApi.vis as vistool\n",
    "#from ochumanApi.ochuman import Poly2Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 360\n",
    "IMG_WIDTH = 480\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "ImgDir = \"C:\\\\Users\\\\pablo\\\\Google Drive\\\\2 TUM\\\\Internships\\\\Tutorials\\\\dataset1\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 367\n",
      "101 101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_train = os.listdir(f\"{ImgDir}images_prepped_train\\\\\")\n",
    "labels_train = os.listdir(f\"{ImgDir}annotations_prepped_train\\\\\")\n",
    "\n",
    "print(len(features_train), len(labels_train))\n",
    "\n",
    "features_test = os.listdir(f\"{ImgDir}images_prepped_test\\\\\")\n",
    "labels_test = os.listdir(f\"{ImgDir}annotations_prepped_test\\\\\")\n",
    "\n",
    "print(len(features_test), len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0001TP_006690.png',\n",
       " '0001TP_006720.png',\n",
       " '0001TP_006750.png',\n",
       " '0001TP_006780.png',\n",
       " '0001TP_006810.png',\n",
       " '0001TP_006840.png',\n",
       " '0001TP_006870.png',\n",
       " '0001TP_006900.png',\n",
       " '0001TP_006930.png',\n",
       " '0001TP_006960.png',\n",
       " '0001TP_006990.png',\n",
       " '0001TP_007020.png',\n",
       " '0001TP_007050.png',\n",
       " '0001TP_007080.png',\n",
       " '0001TP_007110.png',\n",
       " '0001TP_007140.png',\n",
       " '0001TP_007170.png',\n",
       " '0001TP_007200.png',\n",
       " '0001TP_007230.png',\n",
       " '0001TP_007260.png',\n",
       " '0001TP_007290.png',\n",
       " '0001TP_007320.png',\n",
       " '0001TP_007350.png',\n",
       " '0001TP_007380.png',\n",
       " '0001TP_007410.png',\n",
       " '0001TP_007440.png',\n",
       " '0001TP_007470.png',\n",
       " '0001TP_007500.png',\n",
       " '0001TP_007530.png',\n",
       " '0001TP_007560.png',\n",
       " '0001TP_007590.png',\n",
       " '0001TP_007620.png',\n",
       " '0001TP_007650.png',\n",
       " '0001TP_007680.png',\n",
       " '0001TP_007710.png',\n",
       " '0001TP_007740.png',\n",
       " '0001TP_007770.png',\n",
       " '0001TP_007800.png',\n",
       " '0001TP_007830.png',\n",
       " '0001TP_007860.png',\n",
       " '0001TP_007890.png',\n",
       " '0001TP_007920.png',\n",
       " '0001TP_007950.png',\n",
       " '0001TP_007980.png',\n",
       " '0001TP_008010.png',\n",
       " '0001TP_008040.png',\n",
       " '0001TP_008070.png',\n",
       " '0001TP_008100.png',\n",
       " '0001TP_008130.png',\n",
       " '0001TP_008160.png',\n",
       " '0001TP_008190.png',\n",
       " '0001TP_008220.png',\n",
       " '0001TP_008250.png',\n",
       " '0001TP_008280.png',\n",
       " '0001TP_008310.png',\n",
       " '0001TP_008340.png',\n",
       " '0001TP_008370.png',\n",
       " '0001TP_008400.png',\n",
       " '0001TP_008430.png',\n",
       " '0001TP_008460.png',\n",
       " '0001TP_008490.png',\n",
       " '0001TP_008520.png',\n",
       " '0006R0_f00930.png',\n",
       " '0006R0_f00960.png',\n",
       " '0006R0_f00990.png',\n",
       " '0006R0_f01020.png',\n",
       " '0006R0_f01050.png',\n",
       " '0006R0_f01080.png',\n",
       " '0006R0_f01110.png',\n",
       " '0006R0_f01140.png',\n",
       " '0006R0_f01170.png',\n",
       " '0006R0_f01200.png',\n",
       " '0006R0_f01230.png',\n",
       " '0006R0_f01260.png',\n",
       " '0006R0_f01290.png',\n",
       " '0006R0_f01320.png',\n",
       " '0006R0_f01350.png',\n",
       " '0006R0_f01380.png',\n",
       " '0006R0_f01410.png',\n",
       " '0006R0_f01440.png',\n",
       " '0006R0_f01470.png',\n",
       " '0006R0_f01500.png',\n",
       " '0006R0_f01530.png',\n",
       " '0006R0_f01560.png',\n",
       " '0006R0_f01590.png',\n",
       " '0006R0_f01620.png',\n",
       " '0006R0_f01650.png',\n",
       " '0006R0_f01680.png',\n",
       " '0006R0_f01710.png',\n",
       " '0006R0_f01740.png',\n",
       " '0006R0_f01770.png',\n",
       " '0006R0_f01800.png',\n",
       " '0006R0_f01830.png',\n",
       " '0006R0_f01860.png',\n",
       " '0006R0_f01890.png',\n",
       " '0006R0_f01920.png',\n",
       " '0006R0_f01950.png',\n",
       " '0006R0_f01980.png',\n",
       " '0006R0_f02010.png',\n",
       " '0006R0_f02040.png',\n",
       " '0006R0_f02070.png',\n",
       " '0006R0_f02100.png',\n",
       " '0006R0_f02130.png',\n",
       " '0006R0_f02160.png',\n",
       " '0006R0_f02190.png',\n",
       " '0006R0_f02220.png',\n",
       " '0006R0_f02250.png',\n",
       " '0006R0_f02280.png',\n",
       " '0006R0_f02310.png',\n",
       " '0006R0_f02340.png',\n",
       " '0006R0_f02370.png',\n",
       " '0006R0_f02400.png',\n",
       " '0006R0_f02430.png',\n",
       " '0006R0_f02460.png',\n",
       " '0006R0_f02490.png',\n",
       " '0006R0_f02520.png',\n",
       " '0006R0_f02550.png',\n",
       " '0006R0_f02580.png',\n",
       " '0006R0_f02610.png',\n",
       " '0006R0_f02640.png',\n",
       " '0006R0_f02670.png',\n",
       " '0006R0_f02700.png',\n",
       " '0006R0_f02730.png',\n",
       " '0006R0_f02760.png',\n",
       " '0006R0_f02790.png',\n",
       " '0006R0_f02820.png',\n",
       " '0006R0_f02850.png',\n",
       " '0006R0_f02880.png',\n",
       " '0006R0_f02910.png',\n",
       " '0006R0_f02940.png',\n",
       " '0006R0_f02970.png',\n",
       " '0006R0_f03000.png',\n",
       " '0006R0_f03030.png',\n",
       " '0006R0_f03060.png',\n",
       " '0006R0_f03090.png',\n",
       " '0006R0_f03120.png',\n",
       " '0006R0_f03150.png',\n",
       " '0006R0_f03180.png',\n",
       " '0006R0_f03210.png',\n",
       " '0006R0_f03240.png',\n",
       " '0006R0_f03270.png',\n",
       " '0006R0_f03300.png',\n",
       " '0006R0_f03330.png',\n",
       " '0006R0_f03360.png',\n",
       " '0006R0_f03390.png',\n",
       " '0006R0_f03420.png',\n",
       " '0006R0_f03450.png',\n",
       " '0006R0_f03480.png',\n",
       " '0006R0_f03510.png',\n",
       " '0006R0_f03540.png',\n",
       " '0006R0_f03570.png',\n",
       " '0006R0_f03600.png',\n",
       " '0006R0_f03630.png',\n",
       " '0006R0_f03660.png',\n",
       " '0006R0_f03690.png',\n",
       " '0006R0_f03720.png',\n",
       " '0006R0_f03750.png',\n",
       " '0006R0_f03780.png',\n",
       " '0006R0_f03810.png',\n",
       " '0006R0_f03840.png',\n",
       " '0006R0_f03870.png',\n",
       " '0006R0_f03900.png',\n",
       " '0006R0_f03930.png',\n",
       " '0016E5_00390.png',\n",
       " '0016E5_00420.png',\n",
       " '0016E5_00450.png',\n",
       " '0016E5_00480.png',\n",
       " '0016E5_00510.png',\n",
       " '0016E5_00540.png',\n",
       " '0016E5_00570.png',\n",
       " '0016E5_00600.png',\n",
       " '0016E5_00630.png',\n",
       " '0016E5_00660.png',\n",
       " '0016E5_00690.png',\n",
       " '0016E5_00720.png',\n",
       " '0016E5_00750.png',\n",
       " '0016E5_00780.png',\n",
       " '0016E5_00810.png',\n",
       " '0016E5_00840.png',\n",
       " '0016E5_00870.png',\n",
       " '0016E5_00901.png',\n",
       " '0016E5_00930.png',\n",
       " '0016E5_00960.png',\n",
       " '0016E5_00990.png',\n",
       " '0016E5_01020.png',\n",
       " '0016E5_01050.png',\n",
       " '0016E5_01080.png',\n",
       " '0016E5_01110.png',\n",
       " '0016E5_01140.png',\n",
       " '0016E5_01170.png',\n",
       " '0016E5_01200.png',\n",
       " '0016E5_01230.png',\n",
       " '0016E5_01260.png',\n",
       " '0016E5_01290.png',\n",
       " '0016E5_01320.png',\n",
       " '0016E5_01350.png',\n",
       " '0016E5_01380.png',\n",
       " '0016E5_01410.png',\n",
       " '0016E5_01440.png',\n",
       " '0016E5_01470.png',\n",
       " '0016E5_01500.png',\n",
       " '0016E5_01530.png',\n",
       " '0016E5_01560.png',\n",
       " '0016E5_01590.png',\n",
       " '0016E5_01620.png',\n",
       " '0016E5_01650.png',\n",
       " '0016E5_01680.png',\n",
       " '0016E5_01710.png',\n",
       " '0016E5_01740.png',\n",
       " '0016E5_01770.png',\n",
       " '0016E5_01800.png',\n",
       " '0016E5_01830.png',\n",
       " '0016E5_01860.png',\n",
       " '0016E5_01890.png',\n",
       " '0016E5_01920.png',\n",
       " '0016E5_01950.png',\n",
       " '0016E5_01980.png',\n",
       " '0016E5_02010.png',\n",
       " '0016E5_02040.png',\n",
       " '0016E5_02070.png',\n",
       " '0016E5_02100.png',\n",
       " '0016E5_02130.png',\n",
       " '0016E5_02160.png',\n",
       " '0016E5_02190.png',\n",
       " '0016E5_02220.png',\n",
       " '0016E5_02250.png',\n",
       " '0016E5_02280.png',\n",
       " '0016E5_02310.png',\n",
       " '0016E5_02340.png',\n",
       " '0016E5_02370.png',\n",
       " '0016E5_02400.png',\n",
       " '0016E5_04350.png',\n",
       " '0016E5_04380.png',\n",
       " '0016E5_04410.png',\n",
       " '0016E5_04440.png',\n",
       " '0016E5_04470.png',\n",
       " '0016E5_04500.png',\n",
       " '0016E5_04530.png',\n",
       " '0016E5_04560.png',\n",
       " '0016E5_04590.png',\n",
       " '0016E5_04620.png',\n",
       " '0016E5_04650.png',\n",
       " '0016E5_04680.png',\n",
       " '0016E5_04710.png',\n",
       " '0016E5_04740.png',\n",
       " '0016E5_04770.png',\n",
       " '0016E5_04800.png',\n",
       " '0016E5_04830.png',\n",
       " '0016E5_04860.png',\n",
       " '0016E5_04890.png',\n",
       " '0016E5_04920.png',\n",
       " '0016E5_04950.png',\n",
       " '0016E5_04980.png',\n",
       " '0016E5_05010.png',\n",
       " '0016E5_05040.png',\n",
       " '0016E5_05070.png',\n",
       " '0016E5_05100.png',\n",
       " '0016E5_05130.png',\n",
       " '0016E5_05160.png',\n",
       " '0016E5_05190.png',\n",
       " '0016E5_05220.png',\n",
       " '0016E5_05250.png',\n",
       " '0016E5_05280.png',\n",
       " '0016E5_05310.png',\n",
       " '0016E5_05340.png',\n",
       " '0016E5_05370.png',\n",
       " '0016E5_05400.png',\n",
       " '0016E5_05430.png',\n",
       " '0016E5_05460.png',\n",
       " '0016E5_05490.png',\n",
       " '0016E5_05520.png',\n",
       " '0016E5_05550.png',\n",
       " '0016E5_05580.png',\n",
       " '0016E5_05610.png',\n",
       " '0016E5_05640.png',\n",
       " '0016E5_05670.png',\n",
       " '0016E5_05700.png',\n",
       " '0016E5_05730.png',\n",
       " '0016E5_05760.png',\n",
       " '0016E5_05790.png',\n",
       " '0016E5_05820.png',\n",
       " '0016E5_05850.png',\n",
       " '0016E5_05880.png',\n",
       " '0016E5_05910.png',\n",
       " '0016E5_05940.png',\n",
       " '0016E5_05970.png',\n",
       " '0016E5_06000.png',\n",
       " '0016E5_06030.png',\n",
       " '0016E5_06060.png',\n",
       " '0016E5_06090.png',\n",
       " '0016E5_06120.png',\n",
       " '0016E5_06150.png',\n",
       " '0016E5_06180.png',\n",
       " '0016E5_06210.png',\n",
       " '0016E5_06240.png',\n",
       " '0016E5_06270.png',\n",
       " '0016E5_06300.png',\n",
       " '0016E5_06330.png',\n",
       " '0016E5_06360.png',\n",
       " '0016E5_06390.png',\n",
       " '0016E5_06420.png',\n",
       " '0016E5_06450.png',\n",
       " '0016E5_06480.png',\n",
       " '0016E5_06510.png',\n",
       " '0016E5_06540.png',\n",
       " '0016E5_06570.png',\n",
       " '0016E5_06600.png',\n",
       " '0016E5_06630.png',\n",
       " '0016E5_06660.png',\n",
       " '0016E5_06690.png',\n",
       " '0016E5_06720.png',\n",
       " '0016E5_06750.png',\n",
       " '0016E5_06780.png',\n",
       " '0016E5_06810.png',\n",
       " '0016E5_06840.png',\n",
       " '0016E5_06870.png',\n",
       " '0016E5_06900.png',\n",
       " '0016E5_06930.png',\n",
       " '0016E5_06960.png',\n",
       " '0016E5_06990.png',\n",
       " '0016E5_07020.png',\n",
       " '0016E5_07050.png',\n",
       " '0016E5_07080.png',\n",
       " '0016E5_07110.png',\n",
       " '0016E5_07140.png',\n",
       " '0016E5_07170.png',\n",
       " '0016E5_07200.png',\n",
       " '0016E5_07230.png',\n",
       " '0016E5_07260.png',\n",
       " '0016E5_07290.png',\n",
       " '0016E5_07320.png',\n",
       " '0016E5_07350.png',\n",
       " '0016E5_07380.png',\n",
       " '0016E5_07410.png',\n",
       " '0016E5_07440.png',\n",
       " '0016E5_07470.png',\n",
       " '0016E5_07500.png',\n",
       " '0016E5_07530.png',\n",
       " '0016E5_07560.png',\n",
       " '0016E5_07590.png',\n",
       " '0016E5_07620.png',\n",
       " '0016E5_07650.png',\n",
       " '0016E5_07680.png',\n",
       " '0016E5_07710.png',\n",
       " '0016E5_07740.png',\n",
       " '0016E5_07770.png',\n",
       " '0016E5_07800.png',\n",
       " '0016E5_07830.png',\n",
       " '0016E5_07860.png',\n",
       " '0016E5_07890.png',\n",
       " '0016E5_07920.png',\n",
       " '0016E5_08190.png',\n",
       " '0016E5_08220.png',\n",
       " '0016E5_08250.png',\n",
       " '0016E5_08280.png',\n",
       " '0016E5_08310.png',\n",
       " '0016E5_08340.png',\n",
       " '0016E5_08370.png',\n",
       " '0016E5_08400.png',\n",
       " '0016E5_08430.png',\n",
       " '0016E5_08460.png',\n",
       " '0016E5_08490.png',\n",
       " '0016E5_08520.png',\n",
       " '0016E5_08550.png',\n",
       " '0016E5_08580.png',\n",
       " '0016E5_08610.png',\n",
       " '0016E5_08640.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalization\n",
    "'''\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for i in range(len(features_train)):\n",
    "    \n",
    "    img_params = cv2.imread(os.path.join(f\"{ImgDir}images_prepped_train\\\\\",features_train[i]))\n",
    "    img_params = img_params / 255.\n",
    "    x_train.append(img_params)\n",
    "    img_label = cv2.imread(os.path.join(f\"{ImgDir}annotations_prepped_train\\\\\",labels_train[i]))\n",
    "    img_label = img_label / 255.\n",
    "    y_train.append(img_label)\n",
    "    \n",
    "    \n",
    "for i in range(len(features_test)):\n",
    "    \n",
    "    img_params = cv2.imread(os.path.join(f\"{ImgDir}images_prepped_test\\\\\",features_test[i]))\n",
    "    img_params = img_params / 255.\n",
    "    x_test.append(img_params)\n",
    "    img_label = cv2.imread(os.path.join(f\"{ImgDir}annotations_prepped_test\\\\\",labels_test[i]))\n",
    "    img_label = img_label / 255.\n",
    "    y_test.append(img_label)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3 ))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    segmentation = Conv2D(3, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[segmentation])\n",
    "\n",
    "    losses = {'seg': 'binary_crossentropy'\n",
    "            }\n",
    "\n",
    "    metrics = {'seg': ['acc']\n",
    "                }\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback): #acquiring class Callback\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = \"intermediate_results_black_background\"\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "        print('Training: epoch {} begins at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        res_dir = \"intermediate_results_black_background/\"\n",
    "        print('Training: epoch {} ends at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "        \n",
    "        for x_test, y_test in keras_generator_train_val_test(batch_size, choice=\"test\"):\n",
    "            break\n",
    "        p = np.reshape(x_test[0], (1, 512, 512, 3))\n",
    "        prediction = self.model.predict(p)\n",
    "\n",
    "        x_img = f\"{res_dir}{epoch}_X_input.jpg\"\n",
    "        y_img = f\"{res_dir}{epoch}_Y_truth.jpg\"\n",
    "        predicted_img = f\"{res_dir}{epoch}_Y_predicted.jpg\"\n",
    "\n",
    "        cv2.imwrite(x_img, x_test[0] * 255.)\n",
    "        cv2.imwrite(y_img, y_test['seg'][0] * 255.)\n",
    "        cv2.imwrite(predicted_img, prediction[0] * 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback \n",
    "\n",
    "class NeptuneLogger(Callback):\n",
    "    def on_batch_end(self, batch, logs=None):  \n",
    "        for metric_name, metric_value in logs.items():\n",
    "            neptune.log_metric(name=metric_name, metric_value)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        for metric_name, metric_value in logs.items():\n",
    "            neptune.log_metric(name=metric_name, metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install neptune-client neptune-tensorboard\n",
    "\n",
    "# the same as above\n",
    "import neptune\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
    " \n",
    "neptune.init('shared/keras-integration', 'ANONYMOUS')\n",
    "neptune.create_experiment('keras-training')\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2, \n",
    "          epochs=10, \n",
    "          callbacks=[NeptuneMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 416, 608, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 416, 608, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 416, 608, 32) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 416, 608, 32) 9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 208, 304, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 208, 304, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 208, 304, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 208, 304, 64) 36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 104, 152, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 104, 152, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 104, 152, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 104, 152, 128 147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 52, 76, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 52, 76, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 52, 76, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 52, 76, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 104, 152, 128 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 104, 152, 256 0           up_sampling2d[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 104, 152, 64) 147520      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 104, 152, 64) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 104, 152, 64) 36928       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 208, 304, 64) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 208, 304, 128 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 208, 304, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 208, 304, 64) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 208, 304, 64) 36928       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 416, 608, 64) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 416, 608, 96) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 416, 608, 32) 27680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 416, 608, 32) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 416, 608, 32) 9248        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seg (Conv2D)                    (None, 416, 608, 3)  99          conv2d_13[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 914,371\n",
      "Trainable params: 914,371\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "don't run\n",
    "'''\n",
    "\n",
    "### to save best models accross iterations\n",
    "model_name = \"models/\"+\"Unet_black_background.h5\"  #file where to save the best model\n",
    "\n",
    "modelcheckpoint = ModelCheckpoint(model_name,\n",
    "                                  monitor='val_loss',\n",
    "                                  mode='auto',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True)\n",
    "###\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
    "\n",
    "callback_list = [modelcheckpoint, lr_callback, MyCustomCallback()] ## why 3 callbacks??\n",
    "\n",
    "history = model.fit_generator(\n",
    "    keras_generator_train_val_test(batch_size, choice=\"train\"),\n",
    "    validation_data = keras_generator_train_val_test(batch_size, choice=\"val\"),\n",
    "    validation_steps = 100,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=epochs,\n",
    "    verbose=1, \n",
    "    shuffle=True,\n",
    "    callbacks = callback_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 416, 608, 3) for input Tensor(\"input_1:0\", shape=(None, 416, 608, 3), dtype=float32), but it was called on an input with incompatible shape (None, 360, 480, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 416, 608, 3) for input Tensor(\"input_1:0\", shape=(None, 416, 608, 3), dtype=float32), but it was called on an input with incompatible shape (None, 360, 480, 3).\n",
      "37/37 [==============================] - 663s 18s/step - loss: 0.1134 - acc: 0.2908\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - 718s 19s/step - loss: 0.0675 - acc: 0.3199\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - 749s 20s/step - loss: 0.0646 - acc: 0.3206\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - 704s 19s/step - loss: 0.0638 - acc: 0.3297\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - 779s 21s/step - loss: 0.0634 - acc: 0.3328\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = epochs, verbose = 1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## where are the generated images???\n",
    "\n",
    "## sth to save the weights as they go on??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback): #to see the mask as it goes on\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
