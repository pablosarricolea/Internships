{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"k,l,m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workflow:\n",
    "\n",
    "1st: \n",
    "refresh how where they\n",
    "\n",
    "images, organizer in library, set them\n",
    "make sure they are in the correct format with the segmentation labels and the images themselves\n",
    "\n",
    "2nd: poerme con el tema de u-net y tensorflow\n",
    "\n",
    "u-net with dropout layers para conseguir uncertainty. what do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myshow(img):\n",
    "    nda = sitk.GetArrayViewFromImage(img)\n",
    "    plt.imshow(nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_t1 = sitk.ReadImage(\"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\\\\BraTS20_Training_001\\\\BraTS20_Training_001_t1.nii.gz\")\n",
    "img_t1ce = sitk.ReadImage(\"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\\\\BraTS20_Training_001\\\\BraTS20_Training_001_t1ce.nii.gz\")\n",
    "img_t2 = sitk.ReadImage(\"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\\\\BraTS20_Training_001\\\\BraTS20_Training_001_t2.nii.gz\")\n",
    "img_flair = sitk.ReadImage(\"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\\\\BraTS20_Training_001\\\\BraTS20_Training_001_flair.nii.gz\")\n",
    "img_seg = sitk.ReadImage(\"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\\\\BraTS20_Training_001\\\\BraTS20_Training_001_seg.nii.gz\")\n",
    "\n",
    "\"\"\"\n",
    "img_t1 = sitk.Cast(img_t1,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_t1ce = sitk.Cast(img_t1ce,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_t2 = sitk.Cast(img,sitk_t2.sitkFloat32) #to ceonvert png to sitk\n",
    "img_flair = sitk.Cast(img_flair,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_seg = sitk.Cast(img_seg,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "\n",
    "print(img.GetSize())\n",
    "print(img.GetOrigin()) # the top left corner usually\n",
    "print(img.GetSpacing()) #physical size of each pixel\n",
    "print(img.GetDirection()) #3D matrix\n",
    "print(img.GetNumberOfComponentsPerPixel()) #number of channels in one pixel\n",
    "\"\"\"\n",
    "\n",
    "width = img_t1.GetWidth()\n",
    "height = img_t1.GetHeight()\n",
    "depth = img_t1.GetDepth()\n",
    "\n",
    "nda_t1 = sitk.GetArrayViewFromImage(img_t1)\n",
    "nda_t1ce = sitk.GetArrayViewFromImage(img_t1ce)\n",
    "nda_t2 = sitk.GetArrayViewFromImage(img_t2)\n",
    "nda_flair = sitk.GetArrayViewFromImage(img_flair)\n",
    "nda_seg = sitk.GetArrayViewFromImage(img_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npa_zslice_t1 = sitk.GetArrayViewFromImage(img_t1)[int(depth/2),:,:]\n",
    "npa_zslice_t1ce = sitk.GetArrayViewFromImage(img_t1ce)[int(depth/2),:,:]\n",
    "npa_zslice_t2 = sitk.GetArrayViewFromImage(img_t2)[int(depth/2),:,:]\n",
    "npa_zslice_flair = sitk.GetArrayViewFromImage(img_flair)[int(depth/2),:,:]\n",
    "npa_zslice_seg = sitk.GetArrayViewFromImage(img_seg)[int(depth/2),:,:]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "fig.add_subplot(1,5,1)\n",
    "plt.imshow(npa_zslice_t1, cmap=plt.cm.Greys_r)\n",
    "plt.title('T1', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,2)\n",
    "plt.imshow(npa_zslice_t1ce, cmap=plt.cm.Greys_r)\n",
    "plt.title('T1_ce', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,3)\n",
    "plt.imshow(npa_zslice_t2, cmap=plt.cm.Greys_r)\n",
    "plt.title('T2', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,4)\n",
    "plt.imshow(npa_zslice_flair, cmap=plt.cm.Greys_r)\n",
    "plt.title('flair', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,5)\n",
    "plt.imshow(npa_zslice_seg, cmap=plt.cm.Greys_r)\n",
    "plt.title('Segmentation', fontsize=10)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "ImgDir = \"..\\\\data\\\\MICCAI_BraTS2020_TrainingData\"\n",
    "features_path = list()\n",
    "labels_path = list()\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir(ImgDir):\n",
    "    count += 1\n",
    "    if 'Training' in folder and count < 10:\n",
    "        new_dir = f\"{ImgDir}\\\\{folder}\"\n",
    "        data = os.listdir(new_dir)\n",
    "        for files in data:\n",
    "            if 'flair' in files:\n",
    "                features_path.append(new_dir +\"\\\\\"+ files)\n",
    "            if 'seg' in files:\n",
    "                labels_path.append(new_dir +\"\\\\\"+ files)\n",
    "\n",
    "print(len(features_path))\n",
    "print(len(labels_path))\n",
    "\n",
    "X=features_path\n",
    "y=labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor x, y in keras_generator_train_val_test(2, choice=\"train\"):\\n    print(x.shape, y[\\'seg\\'].shape)\\n    break\\n    \\nprint(x.shape, y[\\'seg\\'].shape)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keras_generator_train_val_test(batch_size, choice=\"train\"):\n",
    "\n",
    "    if choice == \"train\":\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "    elif choice == \"val\":\n",
    "        X = X_val\n",
    "        y = y_val\n",
    "    else:\n",
    "        print(\"Invalid Option\")\n",
    "        return False\n",
    "    \n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            rand = random.choice(range(len(X)))\n",
    "            #y_rand = x_rand[:-5]+\"y.jpg\"\n",
    "            \n",
    "            x_path = X[rand]\n",
    "            y_path = y[rand]\n",
    "            \n",
    "            print(x_path)\n",
    "            print(y_path)\n",
    "\n",
    "            x = sitk.GetArrayViewFromImage(sitk.ReadImage(x_path)) / 255.\n",
    "            y = sitk.GetArrayViewFromImage(sitk.ReadImage(y_path)) / 255.\n",
    "            \n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "\n",
    "        x_batch = np.array(x_batch)\n",
    "        # y_batch = np.array(y_batch)\n",
    "\n",
    "        y_batch = {'seg': np.array(y_batch),\n",
    "                #    'cls': np.array(classification_list)\n",
    "                }\n",
    "\n",
    "        yield x_batch, y_batch\n",
    "\"\"\"\n",
    "for x, y in keras_generator_train_val_test(2, choice=\"train\"):\n",
    "    print(x.shape, y['seg'].shape)\n",
    "    break\n",
    "    \n",
    "print(x.shape, y['seg'].shape)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    random_shit = random.choice(np.arange(20))\n",
    "    print(random_shit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for path in features_path:\n",
    "    nda_img = sitk.GetArrayViewFromImage(sitk.ReadImage(path)) / 255.\n",
    "    X.append(nda_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in labels_path:\n",
    "    nda_img = sitk.GetArrayViewFromImage(sitk.ReadImage(path)) / 255.\n",
    "    y.append(nda_img)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = width\n",
    "IMG_WIDTH = height\n",
    "epochs = 50\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 155 ))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    segmentation = Conv2D(155, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[segmentation])\n",
    "\n",
    "    losses = {'seg': 'binary_crossentropy'\n",
    "            }\n",
    "\n",
    "    metrics = {'seg': ['acc']\n",
    "                }\n",
    "    model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = \"intermediate_results_black_background\"\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "        print('Training: epoch {} begins at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        res_dir = \"intermediate_results_black_background/\"\n",
    "        print('Training: epoch {} ends at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "        \n",
    "        for x_test, y_test in keras_generator_train_val_test(batch_size, choice=\"test\"):\n",
    "            break\n",
    "        p = np.reshape(x_test[0], (1, 512, 512, 3))\n",
    "        prediction = self.model.predict(p)\n",
    "\n",
    "        x_img = f\"{res_dir}{epoch}_X_input.jpg\"\n",
    "        y_img = f\"{res_dir}{epoch}_Y_truth.jpg\"\n",
    "        predicted_img = f\"{res_dir}{epoch}_Y_predicted.jpg\"\n",
    "\n",
    "        cv2.imwrite(x_img, x_test[0] * 255.)\n",
    "        cv2.imwrite(y_img, y_test['seg'][0] * 255.)\n",
    "        cv2.imwrite(predicted_img, prediction[0] * 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 240, 240, 15 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 240, 240, 32) 44672       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 240, 240, 32) 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 240, 240, 32) 9248        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 120, 120, 32) 0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 120, 120, 64) 18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 120, 120, 64) 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 120, 120, 64) 36928       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 60, 60, 64)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 60, 60, 128)  73856       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 60, 60, 128)  0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 60, 60, 128)  147584      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 30, 30, 128)  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 30, 30, 128)  147584      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 30, 30, 128)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 30, 30, 128)  147584      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 60, 60, 128)  0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 60, 60, 256)  0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 60, 60, 64)   147520      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 60, 60, 64)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 60, 60, 64)   36928       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 120, 120, 64) 0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 120, 120, 128 0           up_sampling2d_7[0][0]            \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 120, 120, 64) 73792       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 120, 120, 64) 0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 120, 120, 64) 36928       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 240, 240, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 240, 240, 96) 0           up_sampling2d_8[0][0]            \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 240, 240, 32) 27680       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 240, 240, 32) 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 240, 240, 32) 9248        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "seg (Conv2D)                    (None, 240, 240, 155 5115        conv2d_41[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 963,163\n",
      "Trainable params: 963,163\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    keras_generator_train_val_test(batch_size, choice=\"train\"),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "model_name = \"..\\\\data\\\\Unet_black_background_47_epochs.h5\"\n",
    "\n",
    "batch_size = 2;\n",
    "\n",
    "#modelcheckpoint = ModelCheckpoint(model_name,\n",
    "                                  monitor='val_loss',\n",
    "                                  mode='auto',\n",
    "                                  verbose=1,\n",
    "#                                  save_best_only=True)\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
    "\n",
    "#callback_list = [modelcheckpoint, lr_callback, MyCustomCallback()]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    keras_generator_train_val_test(batch_size, choice=\"train\"),\n",
    "    validation_data = keras_generator_train_val_test(batch_size, choice=\"val\"),\n",
    "    validation_steps = 100,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=epochs,\n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    "    #callbacks = callback_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def keras_generator_train_val_test(batch_size, choice=\"train\"):\n",
    "\n",
    "    if choice == \"train\":\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "    elif choice == \"val\":\n",
    "        X = X_val\n",
    "        y = y_val\n",
    "    else:\n",
    "        print(\"Invalid Option\")\n",
    "        return False\n",
    "        \n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            x = sitk.ReadImage(X[i])\n",
    "            x_np = sitk.GetArrayViewFromImage(x) / 255.\n",
    "            y = sitk.ReadImage(y[i])\n",
    "            y_np = sitk.GetArrayViewFromImage(y) / 255.\n",
    "            \n",
    "            x_batch.append(x_np)\n",
    "            y_batch.append(y_np)\n",
    "\n",
    "        \n",
    "        x_batch = np.array(x_batch)\n",
    "        # y_batch = np.array(y_batch)\n",
    "\n",
    "        y_batch = {'seg': np.array(y_batch),\n",
    "                #    'cls': np.array(classification_list)\n",
    "                }\n",
    "\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "for x, y in keras_generator_train_val_test(2, choice=\"train\"):\n",
    "    break\n",
    "\n",
    "print(x.shape, y['seg'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
