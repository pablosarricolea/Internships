{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "use pickle: https://www.datacamp.com/community/tutorials/pickle-python-tutorial\n",
    "h5py: https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/\n",
    "problems with the generator foooor sure: https://github.com/keras-team/keras/issues/1627\n",
    "\n",
    "TODOs:\n",
    "callback so that it goes printing the predictions\n",
    "visualization of layers to see how it trains: https://github.com/yosinski/deep-visualization-toolbox\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:XLA_GPU:1', '/device:GPU:0', '/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu4 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu7 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu6 + \",\" + gpu5\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "h5py_file_name = 'training.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and create data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgDir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "features_path = list()\n",
    "labels_path = list()\n",
    "count = 0\n",
    "lim = 10\n",
    "\n",
    "for folder in os.listdir(ImgDir):\n",
    "    count +=1\n",
    "    if 'Training' in folder:\n",
    "        new_dir = os.path.join(ImgDir,folder)\n",
    "        data = os.listdir(new_dir)\n",
    "        for files in data:\n",
    "            if 'flair' in files:\n",
    "                features_path.append(os.path.join(new_dir, files))\n",
    "            if 'seg' in files:\n",
    "                labels_path.append(os.path.join(new_dir, files))\n",
    "\n",
    "print(len(features_path))\n",
    "print(len(labels_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_features = np.zeros((len(features_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = features_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_features[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_features = np.concatenate(img_conc_features,axis=2)\n",
    "print(np.shape(img_conc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_labels = np.zeros((len(labels_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = labels_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_labels[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_labels = np.concatenate(img_conc_labels,axis=2)\n",
    "print(np.shape(img_conc_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join('..','data',h5py_file_name), 'a') as f:\n",
    "    f.create_dataset(\"features\", data=img_conc_features, compression=\"gzip\")\n",
    "    f.create_dataset(\"labels\", data=img_conc_labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"features\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"labels\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = X_nib.get_fdata()\n",
    "# labels = y_nib.get_fdata()\n",
    "\n",
    "with h5py.File(os.path.join('..','data',h5py_file_name), \"r\") as f:\n",
    "    images = f[\"features\"][()]\n",
    "    labels = f[\"labels\"][()]\n",
    "\n",
    "batch_size = 32\n",
    "smooth = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/using-custom-building-blocks-in-tensorflow-2-0-550b88eb7aa2\n",
    "\n",
    "class My_Custom_Generator(tf.keras.utils.Sequence):\n",
    "  \n",
    "    def __init__(self, images, labels, batch_size):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.images[:,:,idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[:,:,idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        #240,240,32\n",
    "        batch_x /= 255.\n",
    "        batch_y /= 255.\n",
    "\n",
    "        train_image = []\n",
    "        train_label = []\n",
    "        \n",
    "        #for i in range(0, len(batch_x)):\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            X_new = np.zeros((240, 240 ,3), np.float32)\n",
    "            y_new = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "            X_new[:,:,0] = batch_x[:,:,i]\n",
    "            X_new[:,:,1] = batch_x[:,:,i]\n",
    "            X_new[:,:,2] = batch_x[:,:,i]\n",
    "\n",
    "            y_new[:,:,0] = batch_y[:,:,i]\n",
    "            y_new[:,:,1] = batch_y[:,:,i]\n",
    "            y_new[:,:,2] = batch_y[:,:,i]\n",
    "\n",
    "            train_image.append(X_new)\n",
    "            train_label.append(y_new)\n",
    "\n",
    "            #img_path = batch_x[i]\n",
    "            #label = batch_y[i]\n",
    "            #  # read method takes image path and label and returns corresponding matrices\n",
    "            #image, label_matrix = read(img_path, label)\n",
    "            #train_image.append(image)\n",
    "            #train_label.append(label_matrix)\n",
    "            print(np.shape(train_image), np.array(train_image).dtype, np.array(train_label).dtype)\n",
    "\n",
    "        return np.array(train_image), np.array(train_label)\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(images, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    #def on_epoch_end(self, epoch, logs=None):\n",
    "    #    keys = list(logs.keys())\n",
    "    #    \n",
    "    #    print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "pb = printbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return (1-dice_coef(y_true, y_pred))\n",
    "\n",
    "def get_model():\n",
    "    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    segmentation = Conv2D(3, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[segmentation])   \n",
    "\n",
    "    #model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000000199), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2=get_model()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the fit_generator call to include the callback pb\n",
    "model2.fit(x = my_training_batch_generator, steps_per_epoch = int(len(images) // batch_size), epochs = 2, verbose=2, callbacks=[pb], validation_data=None, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \n",
    "    data_length = len(X_nib.get_fdata()[1,1,:])\n",
    "    chunks = np.floor(data_length / batch_size)\n",
    "    print('A')\n",
    "    X = X_nib.get_fdata()\n",
    "    y = y_nib.get_fdata()\n",
    "    print('B')\n",
    "    X /= 255\n",
    "    y /= 255\n",
    "    print('C')\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        for i in range(int(chunks)):\n",
    "            X_yield = []\n",
    "            y_yield = []\n",
    "\n",
    "            X_mod = X[:,:,i*32:(i+1)*32]\n",
    "            y_mod = y[:,:,i*32:(i+1)*32]\n",
    "            print(np.shape(X_mod))\n",
    "\n",
    "            for j in range(32):\n",
    "                X_new = np.zeros((240, 240 ,3), np.uint8)\n",
    "                X_new[:,:,0] = X_mod[:,:,j]\n",
    "                X_new[:,:,1] = X_mod[:,:,j]\n",
    "                X_new[:,:,2] = X_mod[:,:,j]\n",
    "\n",
    "                X_yield.append(X_new)\n",
    "                print(np.shape(X_yield))\n",
    "\n",
    "                y_new = np.zeros((240, 240 ,3), np.uint8)\n",
    "                y_new[:,:,0] = y_mod[:,:,j]\n",
    "                y_new[:,:,1] = y_mod[:,:,j]\n",
    "                y_new[:,:,2] = y_mod[:,:,j]\n",
    "\n",
    "                y_yield.append(y_new)\n",
    "\n",
    "            yield np.reshape(X_yield,(32,240,240,3)), np.reshape(y_yield,(32,240,240,3))\n",
    "        \n",
    "\n",
    "my_generator = generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_1",
   "language": "python",
   "name": "project_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
