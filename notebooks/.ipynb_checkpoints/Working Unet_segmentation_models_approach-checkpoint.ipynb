{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "good paper about losses:\n",
    "https://arxiv.org/pdf/2006.14822.pdf\n",
    "\n",
    "try freezing the encoder?? what does it mean? --> https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "transfer learning in encoder with tumor relared neural network\n",
    "how to implement dropout\n",
    "number of parameters in network\n",
    "resnet34 or densenet121\n",
    "\n",
    "TODOs:\n",
    "\n",
    "check the activation of layers --> https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "implement shuffling in the generator --> https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb // https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "\n",
    "def get_model_with_dropout(base_model_name='efficientnetb4',activation='sigmoid',dropout = 0.1):\n",
    "    base_model = sm.Unet(base_model_name, encoder_weights='imagenet')\n",
    "    base_model_input = base_model.input\n",
    "    base_model_output = base_model.get_layer('final_conv').output\n",
    "    #add dropout\n",
    "    base_model_output = keras.layers.Dropout(dropout)(base_model_output)\n",
    "    #add activation\n",
    "    output = keras.layers.Activation(activation, name=activation)(base_model_output)\n",
    "    model_dp = keras.models.Model(base_model_input, output)\n",
    "\n",
    "    return model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu4 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu7 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu4\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "h5py_file_name = 'training.hdf5'\n",
    "smooth = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the data and creating data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgDir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "features_path = list()\n",
    "labels_path = list()\n",
    "count = 0\n",
    "lim = 10\n",
    "\n",
    "for folder in os.listdir(ImgDir):\n",
    "    count +=1\n",
    "    if 'Training' in folder:\n",
    "        new_dir = os.path.join(ImgDir,folder)\n",
    "        data = os.listdir(new_dir)\n",
    "        for files in data:\n",
    "            if 'flair' in files:\n",
    "                features_path.append(os.path.join(new_dir, files))\n",
    "            if 'seg' in files:\n",
    "                labels_path.append(os.path.join(new_dir, files))\n",
    "\n",
    "print(len(features_path))\n",
    "print(len(labels_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_features = np.zeros((len(features_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = features_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_features[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_features = np.concatenate(img_conc_features,axis=2)\n",
    "print(np.shape(img_conc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_labels = np.zeros((len(labels_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = labels_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_labels[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_labels = np.concatenate(img_conc_labels,axis=2)\n",
    "print(np.shape(img_conc_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join('..','data',h5py_file_name), 'a') as f:\n",
    "    f.create_dataset(\"features\", data=img_conc_features, compression=\"gzip\")\n",
    "    f.create_dataset(\"labels\", data=img_conc_labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"features\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"labels\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stop = 9001\n",
    "n_images = 10000\n",
    "\n",
    "# n_images = 57195\n",
    "# train_stop = int(np.floor(n_images * 0.9))\n",
    "\n",
    "# images = X_nib.get_fdata()\n",
    "# labels = y_nib.get_fdata()\n",
    "\n",
    "#https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/device:GPU:0\", \"/device:GPU:1\"])\n",
    "# with strategy.scope():\n",
    "\n",
    "#with tf.device(\"/device:GPU:0\"):    \n",
    "\n",
    "with h5py.File(os.path.join('..','data',h5py_file_name), \"r\") as f:\n",
    "    #images_train = f[\"features\"][()] #the whole dataset: 57195 images\n",
    "    #labels_train = f[\"labels\"][()]\n",
    "\n",
    "    images = f[\"features\"]\n",
    "    images_train = tf.constant(images[:,:,:train_stop],dtype=tf.float32) #taking a subsample\n",
    "    images_val = tf.constant(images[:,:,train_stop:n_images+1],dtype=tf.float32)\n",
    "\n",
    "    labels = f[\"labels\"]\n",
    "    labels_train = tf.constant(labels[:,:,:train_stop],dtype=tf.float32)\n",
    "    labels_val = tf.constant(images[:,:,train_stop:n_images+1],dtype=tf.float32)\n",
    "\n",
    "#batch_size = 30 \n",
    "\n",
    "print(labels_val[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_train[:,:,96], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_train[:,:,100], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "\n",
    "BACKBONE = 'resnet34' #'densenet121' \n",
    "CLASSES = ['0','1','2','3','4']\n",
    "LR = 0.0001\n",
    "EPOCHS = 50\n",
    "n_classes = 5\n",
    "BATCH_SIZE = 30\n",
    "decoder_filters = (128, 64, 32, 16, 8)   #standard:(256, 128, 64, 32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "def visualize_histories(**images):\n",
    "    \"\"\"Import as tuples: one = (a,b)\"\"\"\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('epoch')\n",
    "        if i == 0:\n",
    "            plt.ylabel('dice_score')\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.plot(np.asarray(image[0]))\n",
    "        plt.plot(np.asarray(image[1]))\n",
    "        plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    CLASSES = ['0','1','2','3','4']\n",
    "    \n",
    "    def __init__(self, images_train, images_label, classes = None):\n",
    "        self.images_fps = images_train\n",
    "        self.masks_fps = images_label\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        self.ids = len(images_train[1,1,:])\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        X_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3), np.float32)\n",
    "\n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,0] = self.images_fps[:,:,i]\n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,1] = self.images_fps[:,:,i]\n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,2] = self.images_fps[:,:,i]\n",
    "        \n",
    "        y_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET), np.float32)\n",
    "\n",
    "        image = X_new[:,:,:]\n",
    "        \n",
    "        y_new[:IMG_HEIGHT,:IMG_WIDTH] = self.masks_fps[:,:,i]\n",
    "        \n",
    "        mask = y_new\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "#         if mask.shape[-1] != 1:\n",
    "#             background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "#             mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "            \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return (batch[0],batch[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(images_train, labels_train, classes=['0','1','2','3','4'])\n",
    "image, mask = dataset[100]\n",
    "visualize(\n",
    "    image=image[:,:,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    no_tumor=mask[..., 0].squeeze(),\n",
    "    one=mask[..., 1].squeeze(),\n",
    "    two=mask[..., 2].squeeze(),\n",
    "    three=mask[..., 3].squeeze(),\n",
    "    four=mask[..., 4].squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = np.expand_dims(image, axis=0)\n",
    "np.shape(image[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES))  # case for binary and multiclass segmentation\n",
    "# n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation, decoder_filters = decoder_filters)\n",
    "#encoder weights from ImageNet, not pretty realted to tumors, so i delete it, interesting to add other weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_channels(x, indexes, **kwargs):\n",
    "    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n",
    "    backend = K\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        x = backend.permute_dimensions(x, (3, 0, 1, 2))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 2, 3, 0))\n",
    "    else:\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "    return x\n",
    "\n",
    "def get_reduce_axes(per_image, **kwargs):\n",
    "    backend = K\n",
    "    axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    if not per_image:\n",
    "        axes.insert(0, 0)\n",
    "    return axes\n",
    "\n",
    "def gather_channels(*xs, indexes=None, **kwargs):\n",
    "    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n",
    "    if indexes is None:\n",
    "        return xs\n",
    "    elif isinstance(indexes, (int)):\n",
    "        indexes = [indexes]\n",
    "    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    backend = K\n",
    "    if per_image:\n",
    "        x = backend.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return backend.mean(x)\n",
    "\n",
    "def round_if_needed(x, threshold, **kwargs):\n",
    "    backend = K\n",
    "    if threshold is not None:\n",
    "        x = backend.greater(x, threshold)\n",
    "        x = backend.cast(x, backend.floatx())\n",
    "    return x\n",
    "\n",
    "def iou_score(gt, pr, class_weights=1., class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    backend = K\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    print(score)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return score\n",
    "\n",
    "metrics_test = [iou_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    mask0 = y_pred[...,0]\n",
    "    mask1 = y_pred[...,1]\n",
    "    mask2 = y_pred[...,2]\n",
    "    mask3 = y_pred[...,3]\n",
    "    mask4 = y_pred[...,4]\n",
    "    \n",
    "    print(mask4)\n",
    "    \n",
    "    masks = [mask0, mask1, mask2, mask3, mask4]\n",
    "    \n",
    "    true0 = y_true[...,0]\n",
    "    true1 = y_true[...,1]\n",
    "    true2 = y_true[...,2]\n",
    "    true3 = y_true[...,3]\n",
    "    true4 = y_true[...,4]\n",
    "    \n",
    "    print(true4)\n",
    "    \n",
    "    trues = [true0, true1, true2, true3, true4]\n",
    "    \n",
    "    intersection = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        intersection.append(K.sum(trues[i] * masks[i]))\n",
    "    \n",
    "    intersection_test = np.asarray(intersection)\n",
    "    coef_test = (2. * intersection_test + smooth) / (intersection_test + masks + smooth)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    coef =  (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    "    \n",
    "    return coef\n",
    "\n",
    "score = make_scorer(dice_coef, greater_is_better=True)\n",
    "\n",
    "metrics_test2 = [dice_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(ground_truth, prediction):\n",
    "\n",
    "    #for metrics, it's good to round predictions:\n",
    "    prediction = K.round(prediction)\n",
    "\n",
    "    #intersection and totals per class per batch (considers channels last)\n",
    "    intersection = ground_truth * prediction\n",
    "    print(np.shape(intersection))\n",
    "    intersection = K.sum(intersection, axis=[1,2])\n",
    "    ground_truth = K.sum(ground_truth, axis=[1,2])\n",
    "    prediction = K.sum(prediction, axis=[1,2])\n",
    "\n",
    "    dice = ((2 * intersection) + K.epsilon()) / (ground_truth + prediction + K.epsilon())\n",
    "    \n",
    "metrics_test3 = [dice_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_for_class(index):\n",
    "    def dice_inner(true,pred):\n",
    "\n",
    "        #get only the desired class\n",
    "        true = true[:,:,:,index]\n",
    "        pred = pred[:,:,:,index]\n",
    "\n",
    "        #return dice per class\n",
    "        return dice_single(true,pred)\n",
    "    return dice_inner\n",
    "\n",
    "metrics_test4 = [dice_for_class(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4, sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "\n",
    "    \n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "# dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.1, 5, 3, 1, 1])) \n",
    "# focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "# total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "total_loss = sm.losses.DiceLoss(class_weights=np.array([1, 1, 1, 1, 1])) \n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for train images\n",
    "\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=[\"/device:GPU:0\", \"/device:GPU:1\"])\n",
    "#with strategy.scope():\n",
    "\n",
    "        train_dataset = Dataset(\n",
    "            images_train, \n",
    "            labels_train, \n",
    "            classes=CLASSES\n",
    "        )\n",
    "\n",
    "        # Dataset for validation images\n",
    "        valid_dataset = Dataset(\n",
    "            images_val, \n",
    "            labels_val, \n",
    "            classes=CLASSES\n",
    "        )\n",
    "\n",
    "        train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # check shapes for errors\n",
    "        assert train_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3)\n",
    "        assert train_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "    \n",
    "        x_img = os.path.join(res_dir,\"X_input.jpg\")\n",
    "        y_img = os.path.join(res_dir,\"Y_truth.jpg\")\n",
    "        predicted_img = os.path.join(res_dir,f\"{epoch}_Y_predicted.jpg\")\n",
    "        \n",
    "        image, gt_mask = train_dataset[100]\n",
    "        #image = np.expand_dims(image, axis=0)\n",
    "        pr_mask = self.model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "        gt_mask_vis = gt_mask[...,0:3]\n",
    "        pr_mask_vis = pr_mask[...,0:3]\n",
    "\n",
    "#         visualize(\n",
    "#             image=denormalize(image.squeeze()),\n",
    "#             gt_mask_vis=gt_mask_vis.squeeze(),\n",
    "#             pr_mask_vis=pr_mask_vis.squeeze(),\n",
    "#         )\n",
    "\n",
    "        cv2.imwrite(x_img, image[:,:,0])\n",
    "        cv2.imwrite(y_img, gt_mask_vis.squeeze())\n",
    "        cv2.imwrite(predicted_img, pr_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, prediction[0,:,:,:] * 255.)\n",
    "        \n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_2/cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*BATCH_SIZE)\n",
    "\n",
    "\n",
    "callbacks = [pb, cp_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_dataloader, \n",
    "    steps_per_epoch=len(train_dataloader), \n",
    "    epochs=EPOCHS,\n",
    "    verbose = 0,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=valid_dataloader, \n",
    "    validation_steps=len(valid_dataloader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"unet_brats.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path)\n",
    "# Restore the weights\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['f1-score'])\n",
    "plt.plot(history.history['val_f1-score'])\n",
    "plt.title('Model f1-score')\n",
    "plt.ylabel('f1-score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [50]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,1:4].squeeze(),\n",
    "        pr_mask=pr_mask[...,0:3].squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = sm.Unet('resnet34', classes = 5, input_shape=(IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3))\n",
    "# model.compile(\n",
    "#     'Adam',\n",
    "#     loss=sm.losses.bce_jaccard_loss,\n",
    "#     metrics=[sm.metrics.iou_score],\n",
    "# )\n",
    "# history = model.fit_generator(train_dataloader, epochs = 20, verbose=1, validation_data=None, class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_feat_dir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\")\n",
    "img_feat = nib.load(test_img_feat_dir)\n",
    "imgarr_feat = img_feat.get_fdata()\n",
    "test_img_feat_slice = imgarr_feat[:,:,100]\n",
    "test_img = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "test_img[:,:,0] = test_img_feat_slice\n",
    "test_img[:,:,1] = test_img_feat_slice\n",
    "test_img[:,:,2] = test_img_feat_slice\n",
    "\n",
    "plt.imshow(test_img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_predicted_3 = os.path.join(\"..\",\"data\",\"test_images\",\"3_Y_predicted.jpg\")\n",
    "directory_predicted_29 = os.path.join(\"..\",\"data\",\"test_images\",\"29_Y_predicted.jpg\")\n",
    "directory_predicted_39 = os.path.join(\"..\",\"data\",\"test_images\",\"39_Y_predicted.jpg\")\n",
    "directory_predicted_49 = os.path.join(\"..\",\"data\",\"test_images\",\"49_Y_predicted.jpg\")\n",
    "directory_y = os.path.join(\"..\",\"data\",\"test_images\",\"Y_truth.jpg\")\n",
    "directory_X = os.path.join(\"..\",\"data\",\"test_images\",\"X_input.jpg\")\n",
    "\n",
    "visualize(\n",
    "    input_image=cv2.imread(directory_X,0).squeeze(),\n",
    "    ground_truth=cv2.imread(directory_y,0).squeeze(),\n",
    "    predicted_3=cv2.imread(directory_predicted_3,0),\n",
    "    predicted_29=cv2.imread(directory_predicted_29,0),\n",
    "    predicted_39=cv2.imread(directory_predicted_39,0),\n",
    "    predicted_49=cv2.imread(directory_predicted_39,0),### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_1",
   "language": "python",
   "name": "project_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
