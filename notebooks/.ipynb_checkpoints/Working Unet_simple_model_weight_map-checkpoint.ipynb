{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = [0.1 1 1 1 1]\n",
    "# gpu 5\n",
    "# cell of checkpoints not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "at some point try focal_loss (see below) caus ea dude said it could work for my problem\n",
    "\n",
    "let's pass the weight map with y_true casue it's the only thing that can accept the loss function\n",
    "\n",
    "i have a utilities preprocessing notebook --> check it out\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow import keras\n",
    "# import segmentation_models as sm\n",
    "\n",
    "# def get_model_with_dropout(base_model_name='efficientnetb4',activation='sigmoid',dropout = 0.1):\n",
    "#     base_model = sm.Unet(base_model_name, encoder_weights='imagenet')\n",
    "#     base_model_input = base_model.input\n",
    "#     base_model_output = base_model.get_layer('final_conv').output\n",
    "#     #add dropout\n",
    "#     base_model_output = keras.layers.Dropout(dropout)(base_model_output)\n",
    "#     #add activation\n",
    "#     output = keras.layers.Activation(activation, name=activation)(base_model_output)\n",
    "#     model_dp = keras.models.Model(base_model_input, output)\n",
    "\n",
    "#     return model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu7 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu4 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu4# + \",\" + gpu6\n",
    "print(get_available_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "from numpy.core.umath_tests import inner1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from helperFunctions import visualize, denormalize, visualize_histories, load_images_from_hdf5\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "train_begin = 0\n",
    "train_stop = 20000\n",
    "n_images = 21000\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "# h5py_file_name = 'delete.hdf5'\n",
    "#h5py_file_name = 'brats2020_full_normalized.hdf5'\n",
    "smooth = 1e-4\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "CLASSES = ['0','1','2','3','4']\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "n_classes = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dropout = 0.2\n",
    "reducing_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_stop - train_begin, n_channels))\n",
    "valid_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, n_images - train_stop + 1, n_channels))\n",
    "\n",
    "train_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_stop - train_begin,2))\n",
    "valid_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, n_images - train_stop + 1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "# dataset_directory = os.path.join(\"..\",\"data\",\"can_be_deleted.hdf5\")\n",
    "\n",
    "h5py_file_name = 't1_images.hdf5'\n",
    "\n",
    "path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "dataset_directory_t1 = os.path.join(\"..\",\"data\", 't1_images.hdf5')\n",
    "dataset_directory_t1ce = os.path.join(\"..\",\"data\", 't1ce_images.hdf5')\n",
    "dataset_directory_t2 = os.path.join(\"..\",\"data\", 't2_images.hdf5')\n",
    "dataset_directory_flair = os.path.join(\"..\",\"data\", 'flair_images.hdf5')\n",
    "dataset_directory_seg = os.path.join(\"..\",\"data\", 'seg_images.hdf5')\n",
    "dataset_directory_weight_map = os.path.join(\"..\",\"data\", 'weight_map.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,1], valid_images[...,1] = load_images_from_hdf5(dataset_directory_t1ce,train_begin,train_stop,n_images)\n",
    "train_images[...,2], valid_images[...,2] = load_images_from_hdf5(dataset_directory_t2,train_begin,train_stop,n_images)\n",
    "train_images[...,0], valid_images[...,0] = load_images_from_hdf5(dataset_directory_flair,train_begin,train_stop,n_images)\n",
    "\n",
    "train_labels[...,0], valid_labels[...,0] = load_images_from_hdf5(dataset_directory_seg,train_begin,train_stop,n_images)\n",
    "train_labels[...,1], valid_labels[...,1] = load_images_from_hdf5(dataset_directory_weight_map,train_begin,train_stop,n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 99\n",
    "\n",
    "visualize(\n",
    "    flair=train_images[...,slice_num,0].squeeze(),\n",
    "    t1ce=train_images[...,slice_num,1].squeeze(),\n",
    "    t2=train_images[...,slice_num,2].squeeze(),\n",
    "    \n",
    "    seg=train_labels[...,slice_num,0].squeeze(),\n",
    "    weight_map=train_labels[...,slice_num,1].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, images_train, images_label, classes = CLASSES):\n",
    "        \n",
    "        self.images_fps = images_train\n",
    "        self.masks_fps = images_label[...,0]\n",
    "        self.class_weights = images_label[...,1]\n",
    "        self.classes = classes\n",
    "        self.class_values = [self.classes.index(cls.lower()) for cls in self.classes]\n",
    "        self.ids = np.shape(self.images_fps)[2]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        X_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels))\n",
    "        y_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET))\n",
    "        y_weightmap = np.ones((IMG_HEIGHT_UNET, IMG_WIDTH_UNET)) * 0.1\n",
    "        \n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,0] = self.images_fps[:,:,i,0]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,1] = self.images_fps[:,:,i,1]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,2] = self.images_fps[:,:,i,2]\n",
    "        #X_new[:IMG_HEIGHT,:IMG_HEIGHT,3] = self.images_fps[:,:,i,3]\n",
    "               \n",
    "        y_new[:IMG_HEIGHT,:IMG_HEIGHT] = self.masks_fps[:,:,i]\n",
    "        y_weightmap[:IMG_HEIGHT,:IMG_HEIGHT] = self.class_weights[:,:,i]\n",
    "        \n",
    "        y_return = np.append(tf.keras.utils.to_categorical(y_new, num_classes=n_classes), y_weightmap[..., np.newaxis], axis=2)\n",
    "        \n",
    "        return X_new, y_return\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        #self.indexes = np.arange(len(dataset))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #t = time.time()\n",
    "        \n",
    "        if \"data\" in dir():\n",
    "            del data\n",
    "        if \"batch\" in dir():\n",
    "            del batch\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [np.arange(len(self.dataset))[k] for k in indexes]\n",
    "\n",
    "        data = []\n",
    "        batch = []\n",
    "        \n",
    "        for j in list_IDs_temp:\n",
    "\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        \n",
    "        #elapsed = time.time() - t\n",
    "        #print(elapsed)\n",
    "\n",
    "        return (batch[0],batch[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import cartesian\n",
    "\n",
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "# def HausdorffDist(A,B):\n",
    "#     # https://github.com/zhengyang-wang/3D-Unet--Tensorflow/blob/master/utils/HausdorffDistance.py\n",
    "#     D_mat = np.sqrt(inner1d(A,A)[np.newaxis].T + inner1d(B,B)-2*(np.dot(A,B.T)))\n",
    "#     # Find DH\n",
    "#     dH = np.max(np.array([np.max(np.min(D_mat,axis=0)),np.max(np.min(D_mat,axis=1))]))\n",
    "#     return(dH)\n",
    "\n",
    "def weighted_hausdorff_distance(w, h, alpha = 0.95):\n",
    "    all_img_locations = tf.convert_to_tensor(cartesian([np.arange(w),\n",
    "                                               np.arange(h)]), dtype=tf.float32)\n",
    "    max_dist = math.sqrt(w ** 2 + h ** 2)\n",
    "\n",
    "    def hausdorff_loss(y_true, y_pred):\n",
    "        def loss(y_true, y_pred):\n",
    "            eps = 1e-6\n",
    "            y_true = K.reshape(y_true, [w, h])\n",
    "            gt_points = K.cast(tf.where(y_true > 0.5), dtype=tf.float32)\n",
    "            num_gt_points = tf.shape(gt_points)[0]\n",
    "            y_pred = K.flatten(y_pred)\n",
    "            p = y_pred\n",
    "            p_replicated = tf.squeeze(K.repeat(tf.expand_dims(p, axis=-1), \n",
    "                                                num_gt_points))\n",
    "            d_matrix = cdist(all_img_locations, gt_points)\n",
    "            num_est_pts = tf.reduce_sum(p)\n",
    "            term_1 = (1 / (num_est_pts + eps)) * K.sum(p * K.min(d_matrix, 1))\n",
    "\n",
    "            d_div_p = K.min((d_matrix + eps) / (p_replicated ** alpha + (eps / max_dist)), 0)\n",
    "            d_div_p = K.clip(d_div_p, 0, max_dist)\n",
    "            term_2 = K.mean(d_div_p, axis=0)\n",
    "\n",
    "            return term_1 + term_2\n",
    "\n",
    "        batched_losses = tf.map_fn(lambda x:\n",
    "                                   loss(x[0], x[1]),\n",
    "                                   (y_true, y_pred),\n",
    "                                   dtype=tf.float32)\n",
    "        return K.mean(tf.stack(batched_losses))\n",
    "\n",
    "    return hausdorff_loss\n",
    "\n",
    "def DiceScore(individual_dices):\n",
    "    #individual_dices: array containing dice scores for each class\n",
    "    return np.mean(individual_dices)\n",
    "\n",
    "def Sensitivity(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def Specificity(TN, FP):\n",
    "    return TN / (FP + TN)\n",
    "\n",
    "metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import cartesian\n",
    "\n",
    "class dice_loss:\n",
    "    \n",
    "    def __init__ (self, true, pred, index):\n",
    "        self.y_true = true[...,0:4]\n",
    "        self.y_pred = pred\n",
    "        self.index = index\n",
    "        \n",
    "    def dice_function(self):\n",
    "        return dice_single(self.y_true[...,self.index], self.y_pred[...,self.index])\n",
    "        \n",
    "        \n",
    "    def dice_single(true,pred):\n",
    "        true = K.batch_flatten(true)\n",
    "        pred = K.batch_flatten(pred)\n",
    "        pred = K.round(pred)\n",
    "\n",
    "        intersection = K.sum(true * pred, axis=-1)\n",
    "        true = K.sum(true, axis=-1)\n",
    "        pred = K.sum(pred, axis=-1)\n",
    "\n",
    "        return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "metrics_test6_weights = [dice_loss(index = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sth(true,pred,index = 0):\n",
    "    true = true[...,0:4]\n",
    "    def dice(true,pred,index = index):\n",
    "        true = true[:,:,:,index]\n",
    "        pred = pred[:,:,:,index]\n",
    "        return dice_single(true,pred)\n",
    "    return dice   \n",
    "\n",
    "metric6 = [sth]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "loss=[penalized_loss(noise=output2)\n",
    "#calculates dice considering an input with a single class\n",
    "      \n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0_weights(y_true = true[...,0:4],pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1_weights(y_true = true[...,0:4],pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2_weights(y_true = true[...,0:4],pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3_weights(y_true = true[...,0:4],pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4_weights(y_true = true[...,0:4],pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "\n",
    "metrics_test5_weights = [dice_inner_0_weights, dice_inner_1_weights, dice_inner_2_weights, dice_inner_3_weights, dice_inner_4_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    dice_inner_0, \n",
    "    dice_inner_1, \n",
    "    dice_inner_2, \n",
    "    dice_inner_3, \n",
    "    dice_inner_4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    def wcce(y_true, y_pred):\n",
    "        Kweights = K.constant(weights)\n",
    "        if not tf.is_tensor(y_pred): y_pred = K.constant(y_pred)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * Kweights, axis=-1)\n",
    "    return wcce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    if per_image:\n",
    "        x = K.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return K.mean(x)\n",
    "\n",
    "def my_func(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg\n",
    "\n",
    "def dice_loss_weighted(y_true, y_pred):\n",
    "    \n",
    "    arg = my_func([dice_inner_0(y_true, y_pred),dice_inner_1(y_true, y_pred),dice_inner_2(y_true, y_pred),dice_inner_3(y_true, y_pred),dice_inner_4(y_true, y_pred)])\n",
    "    score = average(arg)\n",
    "    return  1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=5):\n",
    "    dice=0\n",
    "    for index in range(numLabels):\n",
    "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
    "    print(dice)\n",
    "    return 1+dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=3, class_weights = [0,1,2]):\n",
    "    dice=0\n",
    "    #sth = tf.Variable(np.empty((), dtype='float32'))\n",
    "    #sth = []\n",
    "    for index in range(numLabels):\n",
    "        dice = tf.unstack(dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index]))\n",
    "        #sth = tf.concat([sth,dice],axis=0)\n",
    "        #sth.append(dice)\n",
    "    weighted_dice = K.constant(sth) * K.constant(class_weights)\n",
    "    return K.constant(1 - np.mean(weighted_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = [0.1,1.8,1.2,0.01,1.2]\n",
    "weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_loss(gt, pr, beta=1, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # calculate score\n",
    "    tp = K.sum(gt * pr, axis=axes)\n",
    "    fp = K.sum(pr, axis=axes) - tp\n",
    "    fn = K.sum(gt, axis=axes) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_channels(x, indexes, **kwargs):\n",
    "    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n",
    "    backend = K\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        x = backend.permute_dimensions(x, (3, 0, 1, 2))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 2, 3, 0))\n",
    "    else:\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "    return x\n",
    "\n",
    "def get_reduce_axes(per_image, **kwargs):\n",
    "    backend = K\n",
    "    axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    if not per_image:\n",
    "        axes.insert(0, 0)\n",
    "    return axes\n",
    "\n",
    "def gather_channels(*xs, indexes=None, **kwargs):\n",
    "    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n",
    "    if indexes is None:\n",
    "        return xs\n",
    "    elif isinstance(indexes, (int)):\n",
    "        indexes = [indexes]\n",
    "    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def round_if_needed(x, threshold, **kwargs):\n",
    "    backend = K\n",
    "    if threshold is not None:\n",
    "        x = backend.greater(x, threshold)\n",
    "        x = backend.cast(x, backend.floatx())\n",
    "    return x\n",
    "\n",
    "def iou_score_loss(gt, pr, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    backend = K\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    print(score)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_binary_crossentropy_weight_map(y_true, y_pred):\n",
    "    print(np.shape(y_true))\n",
    "    [seg0, seg1, seg2, seg3, seg4, weight] = tf.unstack(y_true, 6, axis=2)\n",
    "    \n",
    "    seg = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=2)\n",
    "    print(tf.shape(seg))\n",
    "    seg = tf.expand_dims(seg, -1)\n",
    "    #print(np.shape(seg))\n",
    "    weight = tf.expand_dims(weight, -1)\n",
    "    print(tf.shape(weight))\n",
    "    return tf.reduce_mean(\n",
    "       (K.binary_crossentropy(seg, y_pred)*weight)) / (\n",
    "        tf.reduce_sum(weight) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_loss_weightmap(gt, pr, beta=1, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    \n",
    "    [seg0, seg1, seg2, seg3, seg4, weight] = tf.unstack(gt, 6, axis=3)\n",
    "    gt = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=3)\n",
    "    \n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # calculate score\n",
    "    tp = K.sum(weight[...,np.newaxis] * gt * pr, axis=axes)\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + smooth) / (tf.reduce_sum(weight[...,np.newaxis] * tf.square(pr)) + tf.reduce_sum(gt * weight[...,np.newaxis]))\n",
    "\n",
    "    #K.mean(tf.multiply(weight, score), axis=-1)\n",
    "    \n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[seg0, seg1, seg2, seg3, seg4, weight] = tf.unstack(mask, 6, axis=2)\n",
    "gt = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=2)\n",
    "gt = tf.cast(gt, tf.float32)\n",
    "weight = tf.cast(weight[..., np.newaxis], tf.float32)\n",
    "pr = gt\n",
    "\n",
    "gt, pr = gather_channels(gt, pr, indexes=None)\n",
    "pr = round_if_needed(pr, False)\n",
    "axes = get_reduce_axes(False)\n",
    "\n",
    "# calculate score\n",
    "tp = K.sum(weight * gt * pr, axis=axes)\n",
    "\n",
    "score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "        / (tf.reduce_sum(weight * tf.square(pr)) + tf.reduce_sum(gt * weight))\n",
    "\n",
    "\n",
    "\n",
    "#score = average(score, per_image, class_weights)\n",
    "\n",
    "#K.mean(tf.multiply(weight, score), axis=-1)\n",
    "\n",
    "print(1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://niftynet.readthedocs.io/en/dev/_modules/niftynet/layer/loss_segmentation.html#dice\n",
    "\n",
    "def dice_niftynet(prediction, ground_truth, weight_map=True):\n",
    "    \"\"\"\n",
    "    Function to calculate the dice loss with the definition given in\n",
    "\n",
    "        Milletari, F., Navab, N., & Ahmadi, S. A. (2016)\n",
    "        V-net: Fully convolutional neural\n",
    "        networks for volumetric medical image segmentation. 3DV 2016\n",
    "\n",
    "    using a square in the denominator\n",
    "\n",
    "    :param prediction: the logits\n",
    "    :param ground_truth: the segmentation ground_truth\n",
    "    :param weight_map:\n",
    "    :return: the loss\n",
    "    \"\"\"\n",
    "    prediction = tf.cast(prediction, tf.float32)\n",
    "    if len(ground_truth.shape) == len(prediction.shape):\n",
    "        ground_truth = ground_truth[..., -1]\n",
    "    one_hot = labels_to_one_hot(ground_truth, tf.shape(prediction)[-1])\n",
    "\n",
    "    if weight_map is not None:\n",
    "        num_classes = prediction.shape[1].value\n",
    "        weight_map_nclasses = tf.tile(tf.expand_dims(\n",
    "            tf.reshape(weight_map, [-1]), 1), [1, num_classes])\n",
    "        dice_numerator = 2.0 * tf.sparse_reduce_sum(\n",
    "            weight_map_nclasses * one_hot * prediction, reduction_axes=[0])\n",
    "        dice_denominator = \\\n",
    "            tf.reduce_sum(weight_map_nclasses * tf.square(prediction),\n",
    "                          reduction_indices=[0]) + \\\n",
    "            tf.sparse_reduce_sum(one_hot * weight_map_nclasses,\n",
    "                                 reduction_axes=[0])\n",
    "    else:\n",
    "        dice_numerator = 2.0 * tf.sparse_reduce_sum(\n",
    "            one_hot * prediction, reduction_axes=[0])\n",
    "        dice_denominator = \\\n",
    "            tf.reduce_sum(tf.square(prediction), reduction_indices=[0]) + \\\n",
    "            tf.sparse_reduce_sum(one_hot, reduction_axes=[0])\n",
    "    epsilon = 0.00001\n",
    "\n",
    "    dice_score = (dice_numerator + epsilon) / (dice_denominator + epsilon)\n",
    "    # dice_score.set_shape([num_classes])\n",
    "    # minimising (1 - dice_coefficients)\n",
    "    return 1.0 - tf.reduce_mean(dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://niftynet.readthedocs.io/en/dev/_modules/niftynet/layer/loss_segmentation.html#dice\n",
    "\n",
    "def dice_niftynet_modified(ground_truth, prediction, weight_map=None,num_classes=n_classes):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param prediction: the logits\n",
    "    :param ground_truth: the segmentation ground_truth\n",
    "    :param weight_map:\n",
    "    :return: the loss\n",
    "    \n",
    "    Input shape axis 2 must equal 6, got shape [32,256,256,6]\n",
    "    \n",
    "    \"\"\"\n",
    "    epsilon = 0.0001\n",
    "    \n",
    "    print(\"gt: \", np.shape(ground_truth))\n",
    "    \n",
    "    [seg0, seg1, seg2, seg3, seg4, weight_map] = tf.unstack(ground_truth, 6, axis=3)\n",
    "    \n",
    "#     seg0 = seg0[..., np.newaxis]\n",
    "#     seg1 = seg1[..., np.newaxis]\n",
    "#     seg2 = seg2[..., np.newaxis]\n",
    "#     seg3 = seg3[..., np.newaxis]\n",
    "#     seg4 = seg4[..., np.newaxis]\n",
    "    \n",
    "    ground_truth = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=3)\n",
    "    \n",
    "    print(\"seg0: \", np.shape(seg0), \" weightmap: \", np.shape(weight_map), \" gt: \", np.shape(ground_truth),  \" pr: \", np.shape(prediction))\n",
    "    \n",
    "    #ground_truth = tf.cast(ground_truth, tf.float64)\n",
    "    #weight_map = tf.cast(weight_map[..., np.newaxis], tf.float64)\n",
    "    #prediction = tf.cast(prediction, tf.float64)\n",
    "\n",
    "    dice_numerator = 2.0 * tf.reduce_sum(\n",
    "        weight_map[..., np.newaxis] * ground_truth * prediction)\n",
    "    print(\"num done\", np.shape(dice_numerator))\n",
    "    \n",
    "    dice_denominator = \\\n",
    "        tf.reduce_sum(weight_map[..., np.newaxis] * tf.square(prediction)) + \\\n",
    "        tf.reduce_sum(ground_truth * weight_map[..., np.newaxis])\n",
    "    print(\"denom done\", np.shape(dice_denominator))\n",
    "\n",
    "    dice_score = (dice_numerator + epsilon) / (dice_denominator + epsilon)\n",
    "    # dice_score.set_shape([num_classes])\n",
    "    # minimising (1 - dice_coefficients)\n",
    "    return 1.0 - tf.reduce_mean(dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = n_classes\n",
    "epsilon = 0.0001\n",
    "\n",
    "\n",
    "[seg0, seg1, seg2, seg3, seg4, weight_map] = tf.unstack(mask, 6, axis=2)\n",
    "ground_truth = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=2)\n",
    "\n",
    "ground_truth = tf.cast(ground_truth, tf.float32)\n",
    "weight_map = tf.cast(weight_map[..., np.newaxis], tf.float32)\n",
    "\n",
    "prediction = ground_truth\n",
    "\n",
    "print(np.shape(ground_truth),np.shape(prediction),np.shape(weight_map))\n",
    "\n",
    "dice_numerator = 2.0 * tf.reduce_sum(weight_map * ground_truth * prediction)\n",
    "print(\"num done\", np.shape(dice_numerator))\n",
    "dice_denominator = \\\n",
    "    tf.reduce_sum(weight_map * tf.square(prediction)) + \\\n",
    "    tf.reduce_sum(ground_truth * weight_map)\n",
    "print(\"demon done\", np.shape(tf.reduce_sum(weight_map * tf.square(prediction))))\n",
    "\n",
    "\n",
    "dice_score = (dice_numerator + epsilon) / (dice_denominator + epsilon)\n",
    "# dice_score.set_shape([num_classes])\n",
    "# minimising (1 - dice_coefficients)\n",
    "print(1.0 - tf.reduce_mean(dice_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cross_entropy(y_true, y_pred):\n",
    "    try:\n",
    "        [seg, weight] = tf.unstack(y_true, 2, axis=3)\n",
    "\n",
    "        seg = tf.expand_dims(seg, -1)\n",
    "        weight = tf.expand_dims(weight, -1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    epsilon = tf.convert_to_tensor(10e-8, y_pred.dtype.base_dtype)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    y_pred = tf.math.log(y_pred / (1 - y_pred))\n",
    "\n",
    "    zeros = tf.zeros_like(y_pred, dtype=y_pred.dtype)\n",
    "    cond = (y_pred >= zeros)\n",
    "    relu_logits = tf.select(cond, y_pred, zeros)\n",
    "    neg_abs_logits = tf.select(cond, -y_pred, y_pred)\n",
    "    entropy = tf.add(relu_logits - y_pred * seg, tf.log1p(tf.exp(neg_abs_logits)), name=None)\n",
    "    \n",
    "    return K.mean(tf.multiply(weight, entropy), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(target, output, gamma=2):\n",
    "    output /= K.sum(output, axis=-1, keepdims=True)\n",
    "    eps = K.epsilon()\n",
    "    output = K.clip(output, eps, 1. - eps)\n",
    "    return -K.sum(K.pow(1. - output, gamma) * target * K.log(output),\n",
    "                  axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class hausdorff_distance_nifty(PerComponentScalarEvaluation):\n",
    "#     def metric_from_binarized(self, seg, ref):\n",
    "#         ref_border_dist, seg_border_dist = border_distance(seg, ref, 8)\n",
    "#         return np.max([np.max(ref_border_dist), np.max(seg_border_dist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "\n",
    "#loss = dice_niftynet\n",
    "\n",
    "#loss = f_score_loss\n",
    "loss_map = f_score_loss_weightmap\n",
    "optim = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet(\n",
    "    pretrained_weights = None,\n",
    "    input_size = (IMG_HEIGHT_UNET,IMG_WIDTH_UNET,n_channels),\n",
    "    dropout = dropout,\n",
    "    reducing_factor = reducing_factor,\n",
    "    n_classes = n_classes)\n",
    "model.compile(optim, loss=loss_map)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "train_dataset = Dataset(train_images, train_labels, classes=CLASSES)\n",
    "valid_dataset = Dataset(valid_images, valid_labels, classes=CLASSES)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# check shapes for errors\n",
    "assert train_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels)\n",
    "assert train_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes+1)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    \n",
    "#     def on_train_batch_begin(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "#     def on_train_batch_end(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "#         res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "    \n",
    "#         x_img = os.path.join(res_dir,\"X_input.jpg\")\n",
    "#         y_img = os.path.join(res_dir,\"Y_truth.jpg\")\n",
    "#         predicted_img = os.path.join(res_dir,f\"{epoch}_Y_predicted.jpg\")\n",
    "        \n",
    "#         image, gt_mask = train_dataset[100]\n",
    "#         #image = np.expand_dims(image, axis=0)\n",
    "#         pr_mask = self.model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "#         gt_mask_vis = gt_mask[...,0:3]\n",
    "#         pr_mask_vis = pr_mask[...,0:3]\n",
    "\n",
    "# #         visualize(\n",
    "# #             image=denormalize(image.squeeze()),\n",
    "# #             gt_mask_vis=gt_mask_vis.squeeze(),\n",
    "# #             pr_mask_vis=pr_mask_vis.squeeze(),\n",
    "# #         )\n",
    "\n",
    "#         cv2.imwrite(x_img, image[:,:,0])\n",
    "#         cv2.imwrite(y_img, gt_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, pr_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, prediction[0,:,:,:] * 255.)\n",
    "        \n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "        \n",
    "# pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_0211/cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "STEPS_PER_EPOCH = train_stop / BATCH_SIZE\n",
    "SAVE_PERIOD = 5\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH)\n",
    "    )\n",
    "\n",
    "# history_callback = tf.keras.callbacks.CSVLogger('history.csv',separator=',',append=False)\n",
    "\n",
    "# callbacks = [pb, cp_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = train_dataset[99]\n",
    "\n",
    "visualize(\n",
    "    image=image[...,], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    no_tumor=mask[..., 0].squeeze(),\n",
    "    one=mask[..., 1].squeeze(),\n",
    "    two=mask[..., 2].squeeze(),\n",
    "    three=mask[..., 3].squeeze(),\n",
    "    four=mask[..., 4].squeeze(),\n",
    "    weights = mask[...,5].squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=1.0 \n",
    "class_weights=None\n",
    "class_indexes=None\n",
    "smooth=smooth\n",
    "per_image=False\n",
    "threshold=None\n",
    "\n",
    "[seg0, seg1, seg2, seg3, seg4, weight] = tf.unstack(mask, 6, axis=2)\n",
    "gt = tf.stack([seg0,seg1,seg2,seg3,seg4],axis=2)\n",
    "\n",
    "gt, pr = gather_channels(gt, gt)\n",
    "pr = round_if_needed(pr, threshold)\n",
    "axes = get_reduce_axes(per_image)\n",
    "\n",
    "# calculate score\n",
    "tp = K.sum(gt * pr, axis=axes)\n",
    "fp = K.sum(pr, axis=axes) - tp\n",
    "fn = K.sum(gt, axis=axes) - tp\n",
    "\n",
    "score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "        / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n",
    "#score = average(score, per_image, class_weights)\n",
    "\n",
    "score = K.mean(tf.multiply(weight, score))\n",
    "print(score)\n",
    "print(1-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOF = 99\n",
    "image, mask = train_dataset[SOF]\n",
    "\n",
    "visualize(\n",
    "    image_flair=image[...,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    image_t1ce=image[..., 1].squeeze(),\n",
    "    image_t2=image[..., 2].squeeze(),\n",
    "    data_flair=train_images[..., SOF,0].squeeze(),\n",
    "    data_t1ce=train_images[..., SOF, 1].squeeze(),\n",
    "    data_t2=train_images[..., SOF,2].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    original_image = train_images[...,100,0],\n",
    "    original_labels = train_labels[...,100],\n",
    "    weight_map = weight_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    validation_data=valid_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solutions to RAM memory problem\n",
    "\n",
    "    def __del__(self):\n",
    "        #put termination message\n",
    "        for i in range(self._workers)\n",
    "            self._notificationQueue.put(\"terminate\")\n",
    "        #empty queues, otherwise the workers won't terminate\n",
    "        for i in range(self._max_queue_size):\n",
    "            self._batchQueue.get(timeout=10)\n",
    "            \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for activation of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "\n",
    "\n",
    "def getActivations(layer,stimuli):\n",
    "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
    "    plotNNFilter(units)\n",
    "    \n",
    "    \n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageToUse = image[:,:,0]\n",
    "plt.imshow(np.reshape(imageToUse,[256,256]), interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiGPU and Other Add-ons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/naomifridman/Unet_Brain_tumor_segmentation/blob/master/multiple_gpu_Brats_Unet_segmentation_train_and_predict_ver1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Instantiate the base model (or \"template\" model).\n",
    "# We recommend doing this with under a CPU device scope,\n",
    "# so that the model's weights are hosted on CPU memory.\n",
    "# Otherwise they may end up hosted on a GPU, which would\n",
    "# complicate weight sharing.\n",
    "with tf.device('/cpu:0'):\n",
    "    model = model_unet.unet(input_size = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
    "\n",
    "# Replicates the model on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer = Adam(lr = 0.0001),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath = 'model_unet_4ch_3.hdf5',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True, save_weights_only = True)\n",
    "\n",
    "checkpointer2 = ModelCheckpoint(filepath = 'model_unet_best_acc_4ch_3.hdf5',\n",
    "                               verbose=1, monitor='val_accuracy',\n",
    "                               save_best_only=True, save_weights_only = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.000001, verbose=1,  cooldown=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights('model_unet_4ch_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history3 = parallel_model.fit_generator(gen_train,steps_per_epoch=20,\n",
    "                                        #validation_data =( imtest,lbtest), \n",
    "                              validation_data =gen_test_im, validation_steps=2,\n",
    "                                          \n",
    "                              epochs=100,\n",
    "                    callbacks=[earlystopper, checkpointer, checkpointer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_im(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize_im(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "def visualize_histories(**images):\n",
    "    \"\"\"Import as tuples: one = (a,b)\"\"\"\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('epoch')\n",
    "        if i == 0:\n",
    "            plt.ylabel('dice_score')\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.plot(np.asarray(image[0]))\n",
    "        plt.plot(np.asarray(image[1]))\n",
    "        plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"unet_brats.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(checkpoint_path)\n",
    "# Restore the weights\n",
    "checkpoint_path = os.path.join('..', 'data', 'checkpoints')\n",
    "checkpoint_number = 'cp-0040.ckpt'\n",
    "checkpoint_path = os.path.join(checkpoint_path, checkpoint_number)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_mask = valid_dataset[100]\n",
    "model.evaluate(image[np.newaxis, ...], gt_mask[np.newaxis, ...], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "# plt.figure(figsize=(30, 5))\n",
    "# plt.subplot(121)\n",
    "# plt.plot(history.history['f1-score'])\n",
    "# plt.plot(history.history['val_f1-score'])\n",
    "# plt.title('Model f1-score')\n",
    "# plt.ylabel('f1-score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylim([0,1])\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [80, 100]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,2].squeeze(),\n",
    "        pr_mask=pr_mask[...,2].squeeze(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [80]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize_im(\n",
    "        image=denormalize_im(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,4].squeeze(),\n",
    "        pr_mask=pr_mask[...,4].squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_mappings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(pr_mask[0,:,:,1], cmap = colour_mappings[i],alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr_mask[0,:,:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_feat_dir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\")\n",
    "img_feat = nib.load(test_img_feat_dir)\n",
    "imgarr_feat = img_feat.get_fdata()\n",
    "test_img_feat_slice = imgarr_feat[:,:,100]\n",
    "test_img = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "test_img[:,:,0] = test_img_feat_slice\n",
    "test_img[:,:,1] = test_img_feat_slice\n",
    "test_img[:,:,2] = test_img_feat_slice\n",
    "\n",
    "plt.imshow(test_img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_predicted_3 = os.path.join(\"..\",\"data\",\"test_images\",\"3_Y_predicted.jpg\")\n",
    "directory_predicted_29 = os.path.join(\"..\",\"data\",\"test_images\",\"29_Y_predicted.jpg\")\n",
    "directory_predicted_39 = os.path.join(\"..\",\"data\",\"test_images\",\"20_Y_predicted.jpg\")\n",
    "directory_predicted_49 = os.path.join(\"..\",\"data\",\"test_images\",\"31_Y_predicted.jpg\")\n",
    "directory_y = os.path.join(\"..\",\"data\",\"test_images\",\"Y_truth.jpg\")\n",
    "directory_X = os.path.join(\"..\",\"data\",\"test_images\",\"X_input.jpg\")\n",
    "\n",
    "Helper.visualize(\n",
    "    input_image=cv2.imread(directory_X,0).squeeze(),\n",
    "    ground_truth=cv2.imread(directory_y,0).squeeze(),\n",
    "    predicted_3=cv2.imread(directory_predicted_3,0),\n",
    "    predicted_29=cv2.imread(directory_predicted_29,0),\n",
    "    predicted_39=cv2.imread(directory_predicted_39,0),\n",
    "    predicted_49=cv2.imread(directory_predicted_49,0),### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
