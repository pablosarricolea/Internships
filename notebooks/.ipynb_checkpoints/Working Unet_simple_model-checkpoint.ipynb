{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = [0.1 1 1 1 1]\n",
    "# gpu 5\n",
    "# cell of checkpoints not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "clearly a problem in the database, the minimum number of the image is -0.1 (?)\n",
    "\n",
    "good paper about losses:\n",
    "https://arxiv.org/pdf/2006.14822.pdf\n",
    "\n",
    "transfer learning in encoder with tumor relared neural network\n",
    "how to implement dropout\n",
    "number of parameters in network\n",
    "resnet34 or densenet121\n",
    "\n",
    "TODOs:\n",
    "\n",
    "check the activation of layers --> https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "implement shuffling in the generator --> https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb // https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow import keras\n",
    "# import segmentation_models as sm\n",
    "\n",
    "# def get_model_with_dropout(base_model_name='efficientnetb4',activation='sigmoid',dropout = 0.1):\n",
    "#     base_model = sm.Unet(base_model_name, encoder_weights='imagenet')\n",
    "#     base_model_input = base_model.input\n",
    "#     base_model_output = base_model.get_layer('final_conv').output\n",
    "#     #add dropout\n",
    "#     base_model_output = keras.layers.Dropout(dropout)(base_model_output)\n",
    "#     #add activation\n",
    "#     output = keras.layers.Activation(activation, name=activation)(base_model_output)\n",
    "#     model_dp = keras.models.Model(base_model_input, output)\n",
    "\n",
    "#     return model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu7 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu4 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu5# + \",\" + gpu6\n",
    "print(get_available_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "from numpy.core.umath_tests import inner1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from helperFunctions import visualize, denormalize, visualize_histories, load_images_from_hdf5\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "# h5py_file_name = 'delete.hdf5'\n",
    "#h5py_file_name = 'brats2020_full_normalized.hdf5'\n",
    "smooth = 1e-4\n",
    "\n",
    "train_begin = 0\n",
    "train_stop = 20000\n",
    "n_images = 24000\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "CLASSES = ['0','1','2','3','4']\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "n_classes = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dropout = 0.2\n",
    "reducing_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_stop - train_begin, n_channels))\n",
    "valid_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, n_images - train_stop + 1, n_channels))\n",
    "\n",
    "train_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_stop - train_begin))\n",
    "valid_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, n_images - train_stop + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "# dataset_directory = os.path.join(\"..\",\"data\",\"can_be_deleted.hdf5\")\n",
    "\n",
    "h5py_file_name = 't1_images.hdf5'\n",
    "\n",
    "path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "dataset_directory_t1 = os.path.join(\"..\",\"data\", 't1_images.hdf5')\n",
    "dataset_directory_t1ce = os.path.join(\"..\",\"data\", 't1ce_images.hdf5')\n",
    "dataset_directory_t2 = os.path.join(\"..\",\"data\", 't2_images.hdf5')\n",
    "dataset_directory_flair = os.path.join(\"..\",\"data\", 'flair_images.hdf5')\n",
    "dataset_directory_seg = os.path.join(\"..\",\"data\", 'seg_images.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images[...,0], valid_images[...,0] = load_images_from_hdf5(dataset_directory_t1,train_begin,train_stop,n_images)\n",
    "train_images[...,1], valid_images[...,1] = load_images_from_hdf5(dataset_directory_t1ce,train_begin,train_stop,n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,2], valid_images[...,2] = load_images_from_hdf5(dataset_directory_t2,train_begin,train_stop,n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,0], valid_images[...,0] = load_images_from_hdf5(dataset_directory_flair,train_begin,train_stop,n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, valid_labels = load_images_from_hdf5(dataset_directory_seg,train_begin,train_stop,n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 99\n",
    "\n",
    "visualize(\n",
    "    t1=train_images[...,slice_num,0].squeeze(),\n",
    "    t1ce=train_images[...,slice_num,1].squeeze(),\n",
    "    t2=train_images[...,slice_num,2].squeeze(),\n",
    "    #flair=train_images[...,slice_num,3].squeeze(),\n",
    "    seg=train_labels[...,slice_num].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 200\n",
    "\n",
    "visualize(\n",
    "    flair=valid_images[...,slice_num,0].squeeze(),\n",
    "    t1ce=valid_images[...,slice_num,1].squeeze(),\n",
    "    t2=valid_images[...,slice_num,2].squeeze(),\n",
    "    #flair=valid_images[...,slice_num,3].squeeze(),\n",
    "    seg=valid_labels[...,slice_num].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, images_train, images_label, classes = CLASSES):\n",
    "        \n",
    "        self.images_fps = images_train\n",
    "        self.masks_fps = images_label\n",
    "        self.classes = classes\n",
    "        self.class_values = [self.classes.index(cls.lower()) for cls in self.classes]\n",
    "        self.ids = np.shape(self.images_fps)[2]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        X_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels))\n",
    "        y_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET))\n",
    "        \n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,0] = self.images_fps[:,:,i,0]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,1] = self.images_fps[:,:,i,1]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,2] = self.images_fps[:,:,i,2]\n",
    "        #X_new[:IMG_HEIGHT,:IMG_HEIGHT,3] = self.images_fps[:,:,i,3]\n",
    "               \n",
    "        y_new[:IMG_HEIGHT,:IMG_HEIGHT] = self.masks_fps[:,:,i]\n",
    "        \n",
    "        return X_new, tf.keras.utils.to_categorical(y_new, num_classes=n_classes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        #self.indexes = np.arange(len(dataset))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #t = time.time()\n",
    "        \n",
    "        if \"data\" in dir():\n",
    "            del data\n",
    "        if \"batch\" in dir():\n",
    "            del batch\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [np.arange(len(self.dataset))[k] for k in indexes]\n",
    "\n",
    "        data = []\n",
    "        batch = []\n",
    "        \n",
    "        for j in list_IDs_temp:\n",
    "\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        \n",
    "        #elapsed = time.time() - t\n",
    "        #print(elapsed)\n",
    "\n",
    "        return (batch[0],batch[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import cartesian\n",
    "\n",
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "# def HausdorffDist(A,B):\n",
    "#     # https://github.com/zhengyang-wang/3D-Unet--Tensorflow/blob/master/utils/HausdorffDistance.py\n",
    "#     D_mat = np.sqrt(inner1d(A,A)[np.newaxis].T + inner1d(B,B)-2*(np.dot(A,B.T)))\n",
    "#     # Find DH\n",
    "#     dH = np.max(np.array([np.max(np.min(D_mat,axis=0)),np.max(np.min(D_mat,axis=1))]))\n",
    "#     return(dH)\n",
    "\n",
    "def weighted_hausdorff_distance(w, h, alpha = 0.95):\n",
    "    all_img_locations = tf.convert_to_tensor(cartesian([np.arange(w),\n",
    "                                               np.arange(h)]), dtype=tf.float32)\n",
    "    max_dist = math.sqrt(w ** 2 + h ** 2)\n",
    "\n",
    "    def hausdorff_loss(y_true, y_pred):\n",
    "        def loss(y_true, y_pred):\n",
    "            eps = 1e-6\n",
    "            y_true = K.reshape(y_true, [w, h])\n",
    "            gt_points = K.cast(tf.where(y_true > 0.5), dtype=tf.float32)\n",
    "            num_gt_points = tf.shape(gt_points)[0]\n",
    "            y_pred = K.flatten(y_pred)\n",
    "            p = y_pred\n",
    "            p_replicated = tf.squeeze(K.repeat(tf.expand_dims(p, axis=-1), \n",
    "                                                num_gt_points))\n",
    "            d_matrix = cdist(all_img_locations, gt_points)\n",
    "            num_est_pts = tf.reduce_sum(p)\n",
    "            term_1 = (1 / (num_est_pts + eps)) * K.sum(p * K.min(d_matrix, 1))\n",
    "\n",
    "            d_div_p = K.min((d_matrix + eps) / (p_replicated ** alpha + (eps / max_dist)), 0)\n",
    "            d_div_p = K.clip(d_div_p, 0, max_dist)\n",
    "            term_2 = K.mean(d_div_p, axis=0)\n",
    "\n",
    "            return term_1 + term_2\n",
    "\n",
    "        batched_losses = tf.map_fn(lambda x:\n",
    "                                   loss(x[0], x[1]),\n",
    "                                   (y_true, y_pred),\n",
    "                                   dtype=tf.float32)\n",
    "        return K.mean(tf.stack(batched_losses))\n",
    "\n",
    "    return hausdorff_loss\n",
    "\n",
    "def DiceScore(individual_dices):\n",
    "    #individual_dices: array containing dice scores for each class\n",
    "    return np.mean(individual_dices)\n",
    "\n",
    "def Sensitivity(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def Specificity(TN, FP):\n",
    "    return TN / (FP + TN)\n",
    "\n",
    "metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    dice_inner_0, \n",
    "    dice_inner_1, \n",
    "    dice_inner_2, \n",
    "    dice_inner_3, \n",
    "    dice_inner_4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    def wcce(y_true, y_pred):\n",
    "        Kweights = K.constant(weights)\n",
    "        if not tf.is_tensor(y_pred): y_pred = K.constant(y_pred)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * Kweights, axis=-1)\n",
    "    return wcce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    if per_image:\n",
    "        x = K.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return K.mean(x)\n",
    "\n",
    "def my_func(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg\n",
    "\n",
    "def dice_loss_weighted(y_true, y_pred):\n",
    "    \n",
    "    arg = my_func([dice_inner_0(y_true, y_pred),dice_inner_1(y_true, y_pred),dice_inner_2(y_true, y_pred),dice_inner_3(y_true, y_pred),dice_inner_4(y_true, y_pred)])\n",
    "    score = average(arg)\n",
    "    return  1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=5):\n",
    "    dice=0\n",
    "    for index in range(numLabels):\n",
    "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
    "    print(dice)\n",
    "    return 1+dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=3, class_weights = [0,1,2]):\n",
    "    dice=0\n",
    "    #sth = tf.Variable(np.empty((), dtype='float32'))\n",
    "    #sth = []\n",
    "    for index in range(numLabels):\n",
    "        dice = tf.unstack(dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index]))\n",
    "        #sth = tf.concat([sth,dice],axis=0)\n",
    "        #sth.append(dice)\n",
    "    weighted_dice = K.constant(sth) * K.constant(class_weights)\n",
    "    return K.constant(1 - np.mean(weighted_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1,1.8,1.2,0.01,1.2]\n",
    "#weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_loss(gt, pr, beta=1, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # calculate score\n",
    "    tp = K.sum(gt * pr, axis=axes)\n",
    "    fp = K.sum(pr, axis=axes) - tp\n",
    "    fn = K.sum(gt, axis=axes) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_channels(x, indexes, **kwargs):\n",
    "    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n",
    "    backend = K\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        x = backend.permute_dimensions(x, (3, 0, 1, 2))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 2, 3, 0))\n",
    "    else:\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "    return x\n",
    "\n",
    "def get_reduce_axes(per_image, **kwargs):\n",
    "    backend = K\n",
    "    axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    if not per_image:\n",
    "        axes.insert(0, 0)\n",
    "    return axes\n",
    "\n",
    "def gather_channels(*xs, indexes=None, **kwargs):\n",
    "    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n",
    "    if indexes is None:\n",
    "        return xs\n",
    "    elif isinstance(indexes, (int)):\n",
    "        indexes = [indexes]\n",
    "    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def round_if_needed(x, threshold, **kwargs):\n",
    "    backend = K\n",
    "    if threshold is not None:\n",
    "        x = backend.greater(x, threshold)\n",
    "        x = backend.cast(x, backend.floatx())\n",
    "    return x\n",
    "\n",
    "def iou_score_loss(gt, pr, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    backend = K\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    print(score)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "# loss = dice_niftynet\n",
    "loss = f_score_loss\n",
    "optim = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet(\n",
    "    pretrained_weights = None,\n",
    "    input_size = (IMG_HEIGHT_UNET,IMG_WIDTH_UNET,n_channels),\n",
    "    dropout = dropout,\n",
    "    reducing_factor = reducing_factor,\n",
    "    n_classes = n_classes)\n",
    "model.compile(optim, loss=loss, metrics = METRICS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "train_dataset = Dataset(train_images, train_labels, classes=CLASSES)\n",
    "valid_dataset = Dataset(valid_images, valid_labels, classes=CLASSES)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# check shapes for errors\n",
    "assert train_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels)\n",
    "assert train_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    \n",
    "#     def on_train_batch_begin(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "#     def on_train_batch_end(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "#         res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "    \n",
    "#         x_img = os.path.join(res_dir,\"X_input.jpg\")\n",
    "#         y_img = os.path.join(res_dir,\"Y_truth.jpg\")\n",
    "#         predicted_img = os.path.join(res_dir,f\"{epoch}_Y_predicted.jpg\")\n",
    "        \n",
    "#         image, gt_mask = train_dataset[100]\n",
    "#         #image = np.expand_dims(image, axis=0)\n",
    "#         pr_mask = self.model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "#         gt_mask_vis = gt_mask[...,0:3]\n",
    "#         pr_mask_vis = pr_mask[...,0:3]\n",
    "\n",
    "# #         visualize(\n",
    "# #             image=denormalize(image.squeeze()),\n",
    "# #             gt_mask_vis=gt_mask_vis.squeeze(),\n",
    "# #             pr_mask_vis=pr_mask_vis.squeeze(),\n",
    "# #         )\n",
    "\n",
    "#         cv2.imwrite(x_img, image[:,:,0])\n",
    "#         cv2.imwrite(y_img, gt_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, pr_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, prediction[0,:,:,:] * 255.)\n",
    "        \n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "        \n",
    "# pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_0211/cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "STEPS_PER_EPOCH = train_stop / BATCH_SIZE\n",
    "SAVE_PERIOD = 5\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH)\n",
    "    )\n",
    "\n",
    "# history_callback = tf.keras.callbacks.CSVLogger('history.csv',separator=',',append=False)\n",
    "\n",
    "# callbacks = [pb, cp_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = valid_dataset[80]\n",
    "\n",
    "visualize(\n",
    "    image=image[...,2], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    no_tumor=mask[..., 0].squeeze(),\n",
    "    one=mask[..., 1].squeeze(),\n",
    "    two=mask[..., 2].squeeze(),\n",
    "    three=mask[..., 3].squeeze(),\n",
    "    four=mask[..., 4].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOF = 99\n",
    "image, mask = train_dataset[SOF]\n",
    "\n",
    "visualize(\n",
    "    image_flair=image[...,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    image_t1ce=image[..., 1].squeeze(),\n",
    "    image_t2=image[..., 2].squeeze(),\n",
    "    data_flair=train_images[..., SOF,0].squeeze(),\n",
    "    data_t1ce=train_images[..., SOF, 1].squeeze(),\n",
    "    data_t2=train_images[..., SOF,2].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mask[...,0]), np.shape(image[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\n",
    "    original_image = train_images[...,100,0],\n",
    "    original_labels = train_labels[...,100],\n",
    "    weight_map = weight_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(weight_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    validation_data=valid_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solutions to RAM memory problem\n",
    "\n",
    "    def __del__(self):\n",
    "        #put termination message\n",
    "        for i in range(self._workers)\n",
    "            self._notificationQueue.put(\"terminate\")\n",
    "        #empty queues, otherwise the workers won't terminate\n",
    "        for i in range(self._max_queue_size):\n",
    "            self._batchQueue.get(timeout=10)\n",
    "            \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for activation of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "\n",
    "\n",
    "def getActivations(layer,stimuli):\n",
    "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
    "    plotNNFilter(units)\n",
    "    \n",
    "    \n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageToUse = image[:,:,0]\n",
    "plt.imshow(np.reshape(imageToUse,[256,256]), interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiGPU and Other Add-ons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/naomifridman/Unet_Brain_tumor_segmentation/blob/master/multiple_gpu_Brats_Unet_segmentation_train_and_predict_ver1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Instantiate the base model (or \"template\" model).\n",
    "# We recommend doing this with under a CPU device scope,\n",
    "# so that the model's weights are hosted on CPU memory.\n",
    "# Otherwise they may end up hosted on a GPU, which would\n",
    "# complicate weight sharing.\n",
    "with tf.device('/cpu:0'):\n",
    "    model = model_unet.unet(input_size = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
    "\n",
    "# Replicates the model on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer = Adam(lr = 0.0001),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath = 'model_unet_4ch_3.hdf5',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True, save_weights_only = True)\n",
    "\n",
    "checkpointer2 = ModelCheckpoint(filepath = 'model_unet_best_acc_4ch_3.hdf5',\n",
    "                               verbose=1, monitor='val_accuracy',\n",
    "                               save_best_only=True, save_weights_only = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.000001, verbose=1,  cooldown=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights('model_unet_4ch_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history3 = parallel_model.fit_generator(gen_train,steps_per_epoch=20,\n",
    "                                        #validation_data =( imtest,lbtest), \n",
    "                              validation_data =gen_test_im, validation_steps=2,\n",
    "                                          \n",
    "                              epochs=100,\n",
    "                    callbacks=[earlystopper, checkpointer, checkpointer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_im(colormap,**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap = colormap)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_contour(colormap,**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.contour(np.flipud(image), [0.01, 0.5, 0.95], cmap = colormap)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize_im(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "def visualize_histories(**images):\n",
    "    \"\"\"Import as tuples: one = (a,b)\"\"\"\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('epoch')\n",
    "        if i == 0:\n",
    "            plt.ylabel('dice_score')\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.plot(np.asarray(image[0]))\n",
    "        plt.plot(np.asarray(image[1]))\n",
    "        plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def FPR(FP,TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FNR(FN,TP):\n",
    "    return FN/(FN + TP)\n",
    "\n",
    "\n",
    "sensitivity_train = Sensitivity(np.array(history.history['tp']),np.array(history.history['fn']))\n",
    "specificity_train = Specificity(np.array(history.history['tn']),np.array(history.history['fp']))\n",
    "FPR_train = FPR(np.array(history.history['fp']),np.array(history.history['tn']))\n",
    "FNR_train = FNR(np.array(history.history['fn']),np.array(history.history['tp']))\n",
    "dice_score_train = DiceScore([history.history['dice_inner_0'],history.history['dice_inner_1'],history.history['dice_inner_2'],history.history['dice_inner_4']])\n",
    "\n",
    "print(\"Train: sensitivity: \", sensitivity_train[-1], \", specificity: \", specificity_train[-1], \", dice score: \", dice_score_train)\n",
    "\n",
    "sensitivity_val = Sensitivity(np.array(history.history['val_tp']),np.array(history.history['val_fn']))\n",
    "specificity_val = Specificity(np.array(history.history['val_tn']),np.array(history.history['val_fp']))\n",
    "FPR_train = FPR(np.array(history.history['val_fp']),np.array(history.history['val_tn']))\n",
    "FNR_train = FNR(np.array(history.history['val_fn']),np.array(history.history['val_tp']))\n",
    "dice_score_val = DiceScore([history.history['val_dice_inner_0'],history.history['val_dice_inner_1'],history.history['val_dice_inner_2'],history.history['val_dice_inner_4']])\n",
    "\n",
    "print(\"Validation: sensitivity: \", sensitivity_val[-1], \", specificity: \", specificity_val[-1], \", dice score: \", dice_score_val)\n",
    "\n",
    "total_pixels_train = np.array(history.history['tp'])[-1] + np.array(history.history['fp'])[-1] + np.array(history.history['fn'])[-1] + np.array(history.history['tn'])[-1]\n",
    "total_pixels_val = np.array(history.history['val_tp'])[-1] + np.array(history.history['val_fp'])[-1] + np.array(history.history['val_fn'])[-1] + np.array(history.history['val_tn'])[-1]\n",
    "\n",
    "confusion_mat_train = [[np.array(history.history['tp'])[-1],np.array(history.history['fp'])[-1]],[np.array(history.history['fn'])[-1],np.array(history.history['tn'])[-1]]]\n",
    "confusion_mat_val = [[np.array(history.history['val_tp'])[-1],np.array(history.history['val_fp'])[-1]],[np.array(history.history['val_fn'])[-1],np.array(history.history['val_tn'])[-1]]]/total_pixels_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_mat_val, range(2), range(2))\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt=\".2%\", xticklabels=[\"1\",\"0\"], yticklabels=[\"1\",\"0\"]) # font size\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('prediction')\n",
    "plt.title('Confusion matrix Validation set')\n",
    "\"\"\"\n",
    "wrong labels!!!\n",
    "\"\"\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "# plt.figure(figsize=(30, 5))\n",
    "# plt.subplot(121)\n",
    "# plt.plot(history.history['f1-score'])\n",
    "# plt.plot(history.history['val_f1-score'])\n",
    "# plt.title('Model f1-score')\n",
    "# plt.ylabel('f1-score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylim([0,1])\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [80]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,4].squeeze(),\n",
    "        pr_mask=pr_mask[...,4].squeeze(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [80]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize_im(\n",
    "        image=denormalize_im(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,4].squeeze(),\n",
    "        pr_mask=pr_mask[...,4].squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Weights\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"simple_unet_50_epochs.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "checkpoint_path = os.path.join('..', 'data', 'checkpoints')\n",
    "checkpoint_number = 'cp-0040.ckpt'\n",
    "checkpoint_path = os.path.join(checkpoint_path, checkpoint_number)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_mask = valid_dataset[100]\n",
    "model.evaluate(image[np.newaxis, ...], gt_mask[np.newaxis, ...], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_number = 200\n",
    "simulation_number = 20\n",
    "simulation_array = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes, simulation_number))\n",
    "image, gt_mask = valid_dataset[img_number]\n",
    "\n",
    "for i in range(simulations_number):\n",
    "    simulation_array[...,i] = model.predict(image[np.newaxis, ...]) #axis added where the number of batches goes\n",
    "\n",
    "probability_map_mean = np.mean(simulation_array,axis=3)\n",
    "probability_map_std = np.std(simulation_array,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_probability_4_std = probability_map_std[...,2]\n",
    "plt.imshow(img_test_probability_4_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(probability_map_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = [100,200]\n",
    "np.shape(zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = 2\n",
    "img_test_probability_4 = probability_map[100:200,100:200,4]\n",
    "img_test_probability_2 = probability_map[100:200,100:200,2]\n",
    "#plt.imshow(img_test_probability_4,cmap = 'RdYlGn')\n",
    "\n",
    "visualize_im('viridis',\n",
    "             image = image[...,0],\n",
    "             background = gt_mask[...,0],\n",
    "             one = gt_mask[...,1],\n",
    "             two = gt_mask[...,2],\n",
    "    four = gt_mask[...,4],)\n",
    "\n",
    "visualize_im('viridis',\n",
    "             image = image[100:200,100:200,0],\n",
    "             background = gt_mask[100:200,100:200,0],\n",
    "             one = gt_mask[100:200,100:200,1],\n",
    "             two = gt_mask[100:200,100:200,2],\n",
    "    four = gt_mask[100:200,100:200,4],)\n",
    "\n",
    "visualize_im('RdYlGn',\n",
    "          image = image[100:200,100:200,0],\n",
    "          background = probability_map[100:200,100:200,0],\n",
    "             one = probability_map[100:200,100:200,1],\n",
    "             two = probability_map[100:200,100:200,2],\n",
    "             four = probability_map[100:200,100:200,4],\n",
    ")\n",
    "\n",
    "visualize_contour('RdYlGn',\n",
    "          image = image[100:200,100:200,0],\n",
    "          background = probability_map[100:200,100:200,0],\n",
    "             one = probability_map[100:200,100:200,1],\n",
    "             two = probability_map[100:200,100:200,2],\n",
    "             four = probability_map[100:200,100:200,4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = 4\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(np.flipud(gt_mask[100:200,100:200,class_number]),alpha = 0.5,cmap = 'gray')\n",
    "plt.contour(np.flipud(probability_map[100:200,100:200,class_number]), [0.1, 0.5, 0.9], cmap = 'RdYlGn')\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(str(class_number))\n",
    "plt.show()\n",
    "#plt.contour(np.flipud(img_test_probability_2), [0.1, 0.5, 0.9], cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_feat_dir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\")\n",
    "img_feat = nib.load(test_img_feat_dir)\n",
    "imgarr_feat = img_feat.get_fdata()\n",
    "test_img_feat_slice = imgarr_feat[:,:,100]\n",
    "test_img = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "test_img[:,:,0] = test_img_feat_slice\n",
    "test_img[:,:,1] = test_img_feat_slice\n",
    "test_img[:,:,2] = test_img_feat_slice\n",
    "\n",
    "plt.imshow(test_img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_predicted_3 = os.path.join(\"..\",\"data\",\"test_images\",\"3_Y_predicted.jpg\")\n",
    "directory_predicted_29 = os.path.join(\"..\",\"data\",\"test_images\",\"29_Y_predicted.jpg\")\n",
    "directory_predicted_39 = os.path.join(\"..\",\"data\",\"test_images\",\"20_Y_predicted.jpg\")\n",
    "directory_predicted_49 = os.path.join(\"..\",\"data\",\"test_images\",\"31_Y_predicted.jpg\")\n",
    "directory_y = os.path.join(\"..\",\"data\",\"test_images\",\"Y_truth.jpg\")\n",
    "directory_X = os.path.join(\"..\",\"data\",\"test_images\",\"X_input.jpg\")\n",
    "\n",
    "Helper.visualize(\n",
    "    input_image=cv2.imread(directory_X,0).squeeze(),\n",
    "    ground_truth=cv2.imread(directory_y,0).squeeze(),\n",
    "    predicted_3=cv2.imread(directory_predicted_3,0),\n",
    "    predicted_29=cv2.imread(directory_predicted_29,0),\n",
    "    predicted_39=cv2.imread(directory_predicted_39,0),\n",
    "    predicted_49=cv2.imread(directory_predicted_49,0),### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
