{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu7 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu4 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu6 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu4# + \",\" + gpu6\n",
    "print(get_available_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import tqdm\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from utils_metrics import *\n",
    "from utils_visualize import *\n",
    "from utils_loss import *\n",
    "from model import *\n",
    "from model_dropout_all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "smooth = 1e-4\n",
    "\n",
    "train_size = 250 * IMG_DEPTH\n",
    "valid_size = 69 * IMG_DEPTH\n",
    "test_size = 50 * IMG_DEPTH\n",
    "\n",
    "train_begin = 0\n",
    "train_stop = (250 * IMG_DEPTH) \n",
    "valid_begin = 250 * IMG_DEPTH\n",
    "valid_stop = ((250 + 69) * IMG_DEPTH) \n",
    "test_begin = ((250 + 69) * IMG_DEPTH)\n",
    "n_images = N_IMG * IMG_DEPTH \n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "CLASSES = ['0','1','2','3','4']\n",
    "EPOCHS = 20\n",
    "n_classes = 5\n",
    "\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "dropout = 0.2\n",
    "reducing_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_size, n_channels))\n",
    "valid_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, valid_size, n_channels))\n",
    "\n",
    "train_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, train_size))\n",
    "valid_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.zeros((IMG_HEIGHT, IMG_WIDTH, test_size, n_channels))\n",
    "test_labels = np.zeros((IMG_HEIGHT, IMG_WIDTH, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory_t1 = os.path.join(\"..\",\"data\", 't1_images.hdf5')\n",
    "dataset_directory_t1ce = os.path.join(\"..\",\"data\", 't1ce_images.hdf5')\n",
    "dataset_directory_t2 = os.path.join(\"..\",\"data\", 't2_images.hdf5')\n",
    "dataset_directory_flair = os.path.join(\"..\",\"data\", 'flair_images.hdf5')\n",
    "dataset_directory_seg = os.path.join(\"..\",\"data\", 'seg_images.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,1] = load_images_from_hdf5(dataset_directory_t1ce, train_begin, train_stop)\n",
    "valid_images[...,1] = load_images_from_hdf5(dataset_directory_t1ce, valid_begin, valid_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,2] = load_images_from_hdf5(dataset_directory_t2, train_begin, train_stop)\n",
    "valid_images[...,2] = load_images_from_hdf5(dataset_directory_t2, valid_begin, valid_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[...,0] = load_images_from_hdf5(dataset_directory_flair, train_begin, train_stop)\n",
    "valid_images[...,0] = load_images_from_hdf5(dataset_directory_flair, valid_begin, valid_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = load_images_from_hdf5(dataset_directory_seg, train_begin, train_stop)\n",
    "valid_labels = load_images_from_hdf5(dataset_directory_seg, valid_begin, valid_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test dataset\n",
    "\"\"\"\n",
    "\n",
    "test_images[...,0] = load_images_from_hdf5(dataset_directory_flair, test_begin, n_images)\n",
    "test_images[...,1] = load_images_from_hdf5(dataset_directory_t1ce, test_begin, n_images)\n",
    "test_images[...,2] = load_images_from_hdf5(dataset_directory_t2, test_begin, n_images)\n",
    "test_labels = load_images_from_hdf5(dataset_directory_seg, test_begin, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control images\n",
    "\n",
    "slice_num = 99\n",
    "\n",
    "visualize(\n",
    "    flair=train_images[...,slice_num,0].squeeze(),\n",
    "    t1ce=train_images[...,slice_num,1].squeeze(),\n",
    "    t2=train_images[...,slice_num,2].squeeze(),\n",
    "    #flair=train_images[...,slice_num,3].squeeze(),\n",
    "    seg=train_labels[...,slice_num].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control images\n",
    "\n",
    "slice_num = 200\n",
    "\n",
    "visualize(\n",
    "    flair=valid_images[...,slice_num,0].squeeze(),\n",
    "    t1ce=valid_images[...,slice_num,1].squeeze(),\n",
    "    t2=valid_images[...,slice_num,2].squeeze(),\n",
    "    #flair=valid_images[...,slice_num,3].squeeze(),\n",
    "    seg=valid_labels[...,slice_num].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, images_train, images_label, classes = CLASSES):\n",
    "        \n",
    "        self.images_fps = images_train\n",
    "        self.masks_fps = images_label\n",
    "        self.classes = classes\n",
    "        self.class_values = [self.classes.index(cls.lower()) for cls in self.classes]\n",
    "        self.ids = np.shape(self.images_fps)[2]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        #initialize matrices to desired shape, unet shape\n",
    "        X_new = np.ones((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels)) * self.images_fps[3,3,i,0] #background value\n",
    "        y_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET))\n",
    "        \n",
    "        #fit images into initialized matrices\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,0] = self.images_fps[:,:,i,0]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,1] = self.images_fps[:,:,i,1]\n",
    "        X_new[:IMG_HEIGHT,:IMG_HEIGHT,2] = self.images_fps[:,:,i,2]\n",
    "        \n",
    "        #commented in order to keep 3 instead of 4 channels\n",
    "        #X_new[:IMG_HEIGHT,:IMG_HEIGHT,3] = self.images_fps[:,:,i,3]\n",
    "               \n",
    "        y_new[:IMG_HEIGHT,:IMG_HEIGHT] = self.masks_fps[:,:,i]\n",
    "        \n",
    "        #return function and one-hot-encoded mask\n",
    "        return X_new, tf.keras.utils.to_categorical(y_new, num_classes=n_classes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #just to make sure\n",
    "        if \"data\" in dir():\n",
    "            del data\n",
    "        if \"batch\" in dir():\n",
    "            del batch\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [np.arange(len(self.dataset))[k] for k in indexes]\n",
    "\n",
    "        data = []\n",
    "        batch = []\n",
    "        \n",
    "        for j in list_IDs_temp:\n",
    "\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "\n",
    "        return (batch[0],batch[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    dice_inner_0, \n",
    "    dice_inner_1, \n",
    "    dice_inner_2, \n",
    "    dice_inner_3, \n",
    "    dice_inner_4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1,2.3,1.8,0.01,1.8]\n",
    "#weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    if per_image:\n",
    "        x = K.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return K.mean(x)\n",
    "\n",
    "def _gather_channels(x, indexes, **kwargs):\n",
    "    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n",
    "    backend = K\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        x = backend.permute_dimensions(x, (3, 0, 1, 2))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 2, 3, 0))\n",
    "    else:\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "    return x\n",
    "\n",
    "def get_reduce_axes(per_image, **kwargs):\n",
    "    backend = K\n",
    "    axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    if not per_image:\n",
    "        axes.insert(0, 0)\n",
    "    return axes\n",
    "\n",
    "def gather_channels(*xs, indexes=None, **kwargs):\n",
    "    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n",
    "    if indexes is None:\n",
    "        return xs\n",
    "    elif isinstance(indexes, (int)):\n",
    "        indexes = [indexes]\n",
    "    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def round_if_needed(x, threshold, **kwargs):\n",
    "    backend = K\n",
    "    if threshold is not None:\n",
    "        x = backend.greater(x, threshold)\n",
    "        x = backend.cast(x, backend.floatx())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_loss(gt, pr, beta=1, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # calculate score\n",
    "    tp = K.sum(gt * pr, axis=axes)\n",
    "    fp = K.sum(pr, axis=axes) - tp\n",
    "    fn = K.sum(gt, axis=axes) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score_loss(gt, pr, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    backend = K\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    print(score)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "# loss = dice_niftynet\n",
    "loss = f_score_loss\n",
    "optim = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet(\n",
    "    pretrained_weights = None,\n",
    "    input_size = (IMG_HEIGHT_UNET,IMG_WIDTH_UNET,n_channels),\n",
    "    dropout = dropout,\n",
    "    reducing_factor = reducing_factor,\n",
    "    n_classes = n_classes)\n",
    "model.compile(optim, loss=loss, metrics = METRICS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dropout_all = unet_dropout_all(\n",
    "    pretrained_weights = None,\n",
    "    input_size = (IMG_HEIGHT_UNET,IMG_WIDTH_UNET,n_channels),\n",
    "    dropout = dropout,\n",
    "    reducing_factor = reducing_factor,\n",
    "    n_classes = n_classes)\n",
    "model_dropout_all.compile(optim, loss=loss, metrics = METRICS)\n",
    "model_dropout_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "train_dataset = Dataset(train_images, train_labels, classes=CLASSES)\n",
    "valid_dataset = Dataset(valid_images, valid_labels, classes=CLASSES)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# check shapes for errors\n",
    "assert train_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels)\n",
    "assert train_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "        \n",
    "# pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_0211/cp-{epoch:04d}.ckpt\")\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# STEPS_PER_EPOCH = train_stop / BATCH_SIZE\n",
    "# SAVE_PERIOD = 5\n",
    "\n",
    "# # Create a callback that saves the model's weights every 5 epochs\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_path, \n",
    "#     save_weights_only=True,\n",
    "#     save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH)\n",
    "#     )\n",
    "\n",
    "# # history_callback = tf.keras.callbacks.CSVLogger('history.csv',separator=',',append=False)\n",
    "\n",
    "# # callbacks = [pb, cp_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = valid_dataset[100]\n",
    "\n",
    "visualize(\n",
    "    image=image[...,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    no_tumor=mask[..., 0].squeeze(),\n",
    "    one=mask[..., 1].squeeze(),\n",
    "    two=mask[..., 2].squeeze(),\n",
    "    three=mask[..., 3].squeeze(),\n",
    "    four=mask[..., 4].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOF = 99\n",
    "image, mask = train_dataset[SOF]\n",
    "\n",
    "visualize(\n",
    "    image_flair=image[...,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    image_t1ce=image[..., 1].squeeze(),\n",
    "    image_t2=image[..., 2].squeeze(),\n",
    "    data_flair=train_images[..., SOF,0].squeeze(),\n",
    "    data_t1ce=train_images[..., SOF, 1].squeeze(),\n",
    "    data_t2=train_images[..., SOF,2].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    validation_data=valid_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout_all = model_dropout_all.fit(\n",
    "    train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    validation_data=valid_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"simple_unet_20_epochs_50_dropout_all.ckpt\")\n",
    "history = history_dropout_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "sn.set(font_scale=1.0)\n",
    "\n",
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class 0: \", history.history['dice_inner_0'][9])\n",
    "print(\"class 0 val: \", history.history['val_dice_inner_0'][9])\n",
    "print(\"class 1: \", history.history['dice_inner_1'][9])\n",
    "print(\"class 1 val: \", history.history['val_dice_inner_1'][9])\n",
    "print(\"class 2: \", history.history['dice_inner_2'][9])\n",
    "print(\"class 2 val: \", history.history['val_dice_inner_2'][9])\n",
    "print(\"class 3: \", history.history['dice_inner_3'][9])\n",
    "print(\"class 3 val: \", history.history['val_dice_inner_3'][9])\n",
    "print(\"class 4: \", history.history['dice_inner_4'][9])\n",
    "print(\"class 4 val: \", history.history['val_dice_inner_4'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FPR(FP,TN):\n",
    "    return FP/(FP + TN)\n",
    "\n",
    "def FNR(FN,TP):\n",
    "    return FN/(FN + TP)\n",
    "\n",
    "\n",
    "sensitivity_train = Sensitivity(np.array(history.history['tp']),np.array(history.history['fn']))\n",
    "specificity_train = Specificity(np.array(history.history['tn']),np.array(history.history['fp']))\n",
    "FPR_train = FPR(np.array(history.history['fp']),np.array(history.history['tn']))\n",
    "FNR_train = FNR(np.array(history.history['fn']),np.array(history.history['tp']))\n",
    "dice_score_train = DiceScore([history.history['dice_inner_0'],history.history['dice_inner_1'],history.history['dice_inner_2'],history.history['dice_inner_4']])\n",
    "\n",
    "print(\"Train: sensitivity: \", sensitivity_train[-1], \", specificity: \", specificity_train[-1], \", dice score: \", dice_score_train)\n",
    "\n",
    "sensitivity_val = Sensitivity(np.array(history.history['val_tp']),np.array(history.history['val_fn']))\n",
    "specificity_val = Specificity(np.array(history.history['val_tn']),np.array(history.history['val_fp']))\n",
    "FPR_train = FPR(np.array(history.history['val_fp']),np.array(history.history['val_tn']))\n",
    "FNR_train = FNR(np.array(history.history['val_fn']),np.array(history.history['val_tp']))\n",
    "dice_score_val = DiceScore([history.history['val_dice_inner_0'],history.history['val_dice_inner_1'],history.history['val_dice_inner_2'],history.history['val_dice_inner_4']])\n",
    "\n",
    "print(\"Validation: sensitivity: \", sensitivity_val[-1], \", specificity: \", specificity_val[-1], \", dice score: \", dice_score_val)\n",
    "\n",
    "total_pixels_train = np.array(history.history['tp'])[-1] + np.array(history.history['fp'])[-1] + np.array(history.history['fn'])[-1] + np.array(history.history['tn'])[-1]\n",
    "total_pixels_val = np.array(history.history['val_tp'])[-1] + np.array(history.history['val_fp'])[-1] + np.array(history.history['val_fn'])[-1] + np.array(history.history['val_tn'])[-1]\n",
    "\n",
    "confusion_mat_train = [[np.array(history.history['tp'])[-1],np.array(history.history['fp'])[-1]],[np.array(history.history['fn'])[-1],np.array(history.history['tn'])[-1]]]\n",
    "confusion_mat_val = [[np.array(history.history['val_tp'])[-1],np.array(history.history['val_fp'])[-1]],[np.array(history.history['val_fn'])[-1],np.array(history.history['val_tn'])[-1]]]/total_pixels_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confussion matrix\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_mat_val, range(2), range(2))\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt=\".2%\", xticklabels=[\"1\",\"0\"], yticklabels=[\"1\",\"0\"]) # font size\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('prediction')\n",
    "plt.title('Confusion matrix Validation set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "\n",
    "sn.set(font_scale=1.0)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [100]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model_dropout_all.predict(image[np.newaxis, ...])\n",
    "    visualize_im('RdYlGn',\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,0].squeeze(),\n",
    "        pr_mask=pr_mask[...,0].squeeze(),\n",
    "        difference = gt_mask[...,0].squeeze() - pr_mask[...,0].squeeze(),\n",
    "    )\n",
    "    visualize_im('RdYlGn',\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,1].squeeze(),\n",
    "        pr_mask=pr_mask[...,1].squeeze(),\n",
    "        difference = gt_mask[...,1].squeeze() - pr_mask[...,1].squeeze(),\n",
    "    )\n",
    "    visualize_im('RdYlGn',\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,2].squeeze(),\n",
    "        pr_mask=pr_mask[...,2].squeeze(),\n",
    "        difference = gt_mask[...,2].squeeze() - pr_mask[...,2].squeeze(),\n",
    "    )\n",
    "    visualize_im('RdYlGn',\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,4].squeeze(),\n",
    "        pr_mask=pr_mask[...,4].squeeze(),\n",
    "        difference = gt_mask[...,4].squeeze() - pr_mask[...,4].squeeze(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout_all.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(test_images, test_labels, classes=CLASSES)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "assert test_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels)\n",
    "assert test_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "# checkpoint_path = os.path.join('..', 'data', 'checkpoints')\n",
    "# checkpoint_number = 'cp-0040.ckpt'\n",
    "# checkpoint_path = os.path.join(checkpoint_path, checkpoint_number)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_dropout_all.evaluate(test_dataloader, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dice_score = DiceScore([results[5],results[6],results[7],results[9]])\n",
    "print(test_dice_score)\n",
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pablosarricolea/Deep-learning-with-Python/blob/master/Notebooks/Keract-activation.ipynb\n",
    "from keract import get_activations, display_activations, display_heatmaps\n",
    "\n",
    "image, gt_mask = test_dataset[100]\n",
    "plt.imshow(image[...,1])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Activation network\n",
    "x = image[np.newaxis,...]\n",
    "activations = get_activations(model, x)\n",
    "display_activations(activations, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Heatmap, currenlty not working\n",
    "display_heatmaps(activations, image, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dice_coef(y_true, y_pred_bin):\n",
    "    # shape of y_true and y_pred_bin: (height, width)\n",
    "    intersection = np.sum(y_true * y_pred_bin)\n",
    "    if (np.sum(y_true)==0) and (np.sum(y_pred_bin)==0):\n",
    "        return 1\n",
    "    return (2*intersection) / (np.sum(y_true) + np.sum(y_pred_bin))\n",
    "\n",
    "def dice_single_single(true,pred):\n",
    "    true = np.ndarray.flatten(true)\n",
    "    pred = np.ndarray.flatten(pred)\n",
    "    pred = np.round(pred)\n",
    "\n",
    "    intersection = np.sum(true * pred, axis=-1)\n",
    "    true = np.sum(true, axis=-1)\n",
    "    pred = np.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + 0.00001) / (true + pred + 0.000001)\n",
    "\n",
    "def mean_dice_coef(y_true, y_pred_bin):\n",
    "    # shape of y_true and y_pred_bin: (n_samples, height, width, n_channels)\n",
    "    batch_size = y_true.shape[0]\n",
    "    channel_num = y_true.shape[-1]\n",
    "    mean_dice_channel = 0.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(channel_num):\n",
    "            channel_dice = single_dice_coef(y_true[i, :, :, j], y_pred_bin[i, :, :, j])\n",
    "            mean_dice_channel += channel_dice/(channel_num*batch_size)\n",
    "        print(mean_dice_channel)\n",
    "    return mean_dice_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2img(fig):\n",
    "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "    import io\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img\n",
    "\n",
    "def plot_img(array, i):\n",
    "    plt.imshow(array[i])\n",
    "    plt.grid(False)\n",
    "    \n",
    "def plot_img_with_all_labels(array, image, i):\n",
    "    channel_num = array.shape[-1]\n",
    "    plt.imshow(array[i,...,1],cmap = 'Greens', alpha = 0.8)\n",
    "    plt.imshow(array[i,...,2],cmap = 'Reds', alpha = 0.5)\n",
    "    plt.imshow(array[i,...,4],cmap = 'Blues', alpha = 0.2)\n",
    "    plt.imshow(image[i,...], alpha = 0.3, cmap = 'Greys')\n",
    "    plt.grid(False)\n",
    "    \n",
    "    #to be able to make the gif later\n",
    "    fig = plt.gcf()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.close()\n",
    "    return fig\n",
    "    \n",
    "def plot_contour(array,i):\n",
    "    plt.contour(np.flipud(array[i]), [0.1, 0.5, 0.9], cmap = 'RdYlGn')\n",
    "\n",
    "def plot_contour_with_gt(array, gt, image, i):\n",
    "    plt.imshow(image[i], alpha = 0.3, cmap = 'Greys')\n",
    "    plt.contour(gt[i],alpha = 0.5,cmap = 'gray')\n",
    "    #plt.contour(array[i], [0.1, 0.9], cmap = 'RdYlGn')\n",
    "    \n",
    "    plt.contour(array[i,...,1],cmap = 'Greens', alpha = 0.8)\n",
    "    plt.contour(array[i,...,2],cmap = 'Reds', alpha = 0.5)\n",
    "    plt.contour(array[i,...,4],cmap = 'Blues', alpha = 0.2)\n",
    "    \n",
    "    #to be able to make the gif later\n",
    "    fig = plt.gcf()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.close()\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ =test_dataset[100]\n",
    "y_probas = np.stack([model_dropout_all(image[np.newaxis,...], training=True) for sample in range(100)])\n",
    "y_probas = np.squeeze(y_probas)\n",
    "vis_img = np.ones((100,256,256))\n",
    "for i in range(100):\n",
    "    vis_img[i,...] = image[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(plot_img_with_all_labels,\n",
    "                array = widgets.fixed(y_probas),\n",
    "                image = widgets.fixed(vis_img),\n",
    "                i = widgets.IntSlider(value=0,min=0,max =(100-1),step=1,description='Frame N:',orientation='horizontal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    img.append(fig2img(plot_img_with_all_labels(y_probas, vis_img, i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].save('individual_predictions.gif',\n",
    "               save_all=True, append_images=img[1:], optimize=False, duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_number = 2\n",
    "simulation_number = 10\n",
    "count = 0\n",
    "\n",
    "#initialize saving volumes\n",
    "simulation_array = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes, IMG_DEPTH, simulation_number))\n",
    "gt_volume = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes, IMG_DEPTH))\n",
    "image_volume = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_channels, IMG_DEPTH))\n",
    "dummy_dice = np.zeros((IMG_DEPTH,simulation_number))\n",
    "\n",
    "#iterate across a whole volume\n",
    "for j in range(IMG_DEPTH * (volume_number - 1), IMG_DEPTH * volume_number ):\n",
    "    \n",
    "    image, gt_mask = test_dataset[j]\n",
    "    gt_volume[...,count] = gt_mask\n",
    "    image_volume[...,count] = image\n",
    "    \n",
    "    #running predictions and saving results\n",
    "    for i in range(simulation_number):\n",
    "        \n",
    "        simulation_array[...,count,i] = model_dropout_all(image[np.newaxis,...], training=True)\n",
    "        \n",
    "    count += 1\n",
    "\n",
    "#obtaining the mean of the predictions\n",
    "probability_map_mean = np.mean(simulation_array,axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volume dice coefficient\n",
    "\n",
    "a = np.zeros((4))\n",
    "for i in range(4):\n",
    "    x = np.delete(gt_volume[np.newaxis,...,],3,axis = 3)[0,:,:,i,...]\n",
    "    y = np.delete(probability_map_mean[np.newaxis,...,],3,axis = 3)[0,:,:,i,...]\n",
    "    a[i] = single_dice_coef(y,x)\n",
    "    \n",
    "final_dice = np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting arrays for their widget visualization\n",
    "\n",
    "list_frames_visualization = np.rollaxis(probability_map_mean,3,0)\n",
    "gt_volume_visualization = np.rollaxis(gt_volume,3,0)\n",
    "image_volume_visualization = np.rollaxis(image_volume,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_of_interest = 2\n",
    "label_of_interest = 4\n",
    "\n",
    "corrected_image = np.around(list_frames_visualization,2)\n",
    "thing = gt_volume_visualization[...,label_of_interest]\n",
    "for i in range(155):\n",
    "    corrected_image[i,1:3,1:3] = 0.5 \n",
    "    thing[1,1:3,1:3] = 0.1\n",
    "\n",
    "widgets.interact(plot_contour_with_gt,\n",
    "                array = widgets.fixed(corrected_image),\n",
    "                gt = widgets.fixed(thing),\n",
    "                image = widgets.fixed(image_volume_visualization[...,channel_of_interest]),\n",
    "                i = widgets.IntSlider(value=0,min=0,max =(len(list_frames_visualization)-1),step=1,description='Frame N:',orientation='horizontal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(list_frames_visualization[...,2]))):\n",
    "    img.append(fig2img(plot_contour_with_gt(corrected_image, thing, image_volume_visualization[...,0],i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].save('volume_predictions.gif',\n",
    "               save_all=True, append_images=img[1:], optimize=False, duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "### Network activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#font = ImageFont.truetype('arial.pil')\n",
    "font = ImageFont.load_default()\n",
    "visualkeras.layered_view(model_dropout_all, legend = True, scale_xy=2, scale_z=0.5, font=font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
