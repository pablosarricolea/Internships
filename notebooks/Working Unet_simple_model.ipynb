{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = [0.1 1 1 1 1]\n",
    "# gpu 5\n",
    "# cell of checkpoints not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "clearly a problem in the database, the minimum number of the image is -0.1 (?)\n",
    "\n",
    "good paper about losses:\n",
    "https://arxiv.org/pdf/2006.14822.pdf\n",
    "\n",
    "transfer learning in encoder with tumor relared neural network\n",
    "how to implement dropout\n",
    "number of parameters in network\n",
    "resnet34 or densenet121\n",
    "\n",
    "TODOs:\n",
    "\n",
    "check the activation of layers --> https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "implement shuffling in the generator --> https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb // https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow import keras\n",
    "# import segmentation_models as sm\n",
    "\n",
    "# def get_model_with_dropout(base_model_name='efficientnetb4',activation='sigmoid',dropout = 0.1):\n",
    "#     base_model = sm.Unet(base_model_name, encoder_weights='imagenet')\n",
    "#     base_model_input = base_model.input\n",
    "#     base_model_output = base_model.get_layer('final_conv').output\n",
    "#     #add dropout\n",
    "#     base_model_output = keras.layers.Dropout(dropout)(base_model_output)\n",
    "#     #add activation\n",
    "#     output = keras.layers.Activation(activation, name=activation)(base_model_output)\n",
    "#     model_dp = keras.models.Model(base_model_input, output)\n",
    "\n",
    "#     return model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu4 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu7 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu7# + \",\" + gpu6\n",
    "print(get_available_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "h5py_file_name = 'brats2020_normalized.hdf5'\n",
    "smooth = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the data and creating data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgDir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "features_path = list()\n",
    "labels_path = list()\n",
    "count = 0\n",
    "lim = 10\n",
    "\n",
    "for folder in os.listdir(ImgDir):\n",
    "    count +=1\n",
    "    if 'Training' in folder:\n",
    "        new_dir = os.path.join(ImgDir,folder)\n",
    "        data = os.listdir(new_dir)\n",
    "        for files in data:\n",
    "            if 'flair' in files:\n",
    "                features_path.append(os.path.join(new_dir, files))\n",
    "            if 'seg' in files:\n",
    "                labels_path.append(os.path.join(new_dir, files))\n",
    "\n",
    "print(len(features_path))\n",
    "print(len(labels_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_features = np.zeros((len(features_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = features_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_features[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_features = np.concatenate(img_conc_features,axis=2)\n",
    "print(np.shape(img_conc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_conc_labels = np.zeros((len(labels_path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "path = labels_path\n",
    "\n",
    "for file, i in zip(path,range(len(path))):\n",
    "    img = nib.load(file)\n",
    "    imgarr = img.get_fdata()\n",
    "    img_conc_labels[i,:,:,:] = imgarr\n",
    "    \n",
    "img_conc_labels = np.concatenate(img_conc_labels,axis=2)\n",
    "print(np.shape(img_conc_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join('..','data',h5py_file_name), 'a') as f:\n",
    "    f.create_dataset(\"features\", data=img_conc_features, compression=\"gzip\")\n",
    "    f.create_dataset(\"labels\", data=img_conc_labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"features\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"labels\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_begin = 0\n",
    "train_stop = 20000\n",
    "n_images = 21000\n",
    "\n",
    "# n_images = 57195\n",
    "# train_stop = int(np.floor(n_images * 0.9))\n",
    "\n",
    "#https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/  \n",
    "\n",
    "# with h5py.File(os.path.join('..','data',h5py_file_name), \"r\") as f:\n",
    "#     #images_train = f[\"features\"][()] #the whole dataset: 57195 images\n",
    "#     #labels_train = f[\"labels\"][()]\n",
    "\n",
    "#     images = f[\"features\"]\n",
    "#     images_train = tf.constant(images[:,:,train_begin:train_stop],dtype=tf.float32) #taking a subsample\n",
    "#     images_val = tf.constant(images[:,:,train_stop:n_images+1],dtype=tf.float32)\n",
    "\n",
    "#     labels = f[\"labels\"]\n",
    "#     labels_train = tf.constant(labels[:,:,train_begin:train_stop],dtype=tf.int8)\n",
    "#     labels_val = tf.constant(labels[:,:,train_stop:n_images+1],dtype=tf.int8)\n",
    "\n",
    "# print(images_val[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join('..','data',h5py_file_name), \"r\") as f:\n",
    "    #images_train = f[\"features\"][()] #the whole dataset: 57195 images\n",
    "    #labels_train = f[\"labels\"][()]\n",
    "\n",
    "    images = f[\"features\"]\n",
    "    images_train = images[:,:,train_begin:train_stop]\n",
    "    images_val = images[:,:,train_stop:n_images+1]\n",
    "\n",
    "    labels = f[\"labels\"]\n",
    "    labels_train = labels[:,:,train_begin:train_stop]\n",
    "    labels_val = labels[:,:,train_stop:n_images+1]\n",
    "\n",
    "print(images_val[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train.get_shape().as_list()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_train[:,:,100], interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_train[:,:,100], interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['0','1','2','3','4']\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "n_classes = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "def visualize_histories(**images):\n",
    "    \"\"\"Import as tuples: one = (a,b)\"\"\"\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('epoch')\n",
    "        if i == 0:\n",
    "            plt.ylabel('dice_score')\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.plot(np.asarray(image[0]))\n",
    "        plt.plot(np.asarray(image[1]))\n",
    "        plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, images_train, images_label, classes = CLASSES):\n",
    "        self.images_fps = images_train\n",
    "        self.masks_fps = images_label\n",
    "        self.classes = classes\n",
    "        self.class_values = [self.classes.index(cls.lower()) for cls in self.classes]\n",
    "        self.ids = np.shape(self.images_fps)[2]\n",
    "        #self.ids = images_train.get_shape().as_list()[2]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        X_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3))\n",
    "        y_new = np.zeros((IMG_HEIGHT_UNET, IMG_WIDTH_UNET))\n",
    "        \n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,0] = self.images_fps[:,:,i]\n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,1] = self.images_fps[:,:,i]\n",
    "        X_new[:IMG_HEIGHT,:IMG_WIDTH,2] = self.images_fps[:,:,i]\n",
    "\n",
    "        #image = X_new[:,:,:] / np.max(X_new[:,:,:])\n",
    "        #image = X_new[:,:,:]\n",
    "        \n",
    "        y_new[:IMG_HEIGHT,:IMG_WIDTH] = self.masks_fps[:,:,i]\n",
    "        \n",
    "        #mask = y_new\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        #masks = [(mask == v) for v in self.class_values]\n",
    "        #mask = np.stack(masks, axis=-1)\n",
    "        \n",
    "        #mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "        #if mask.shape[-1] != 1:\n",
    "            #background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            #mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        return X_new, tf.keras.utils.to_categorical(y_new, num_classes=n_classes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        #self.indexes = np.arange(len(dataset))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # collect batch data\n",
    "        #print(\"self indexes: \",self.indexes)\n",
    "        if \"data\" in dir():\n",
    "            del data\n",
    "        if \"batch\" in dir():\n",
    "            del batch\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [np.arange(len(self.dataset))[k] for k in indexes]\n",
    "\n",
    "        #print(\"temporal IDs: \", list_IDs_temp)\n",
    "        #start = i * self.batch_size\n",
    "        #stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        batch = []\n",
    "        \n",
    "        for j in list_IDs_temp:\n",
    "            # data.append(self.dataset[self.indexes[j]])\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "\n",
    "        \n",
    "        return (batch[0],batch[1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "# metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4, sm.metrics.FScore(threshold=0.5)]\n",
    "metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    def wcce(y_true, y_pred):\n",
    "        Kweights = K.constant(weights)\n",
    "        if not tf.is_tensor(y_pred): y_pred = K.constant(y_pred)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * Kweights, axis=-1)\n",
    "    return wcce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    if per_image:\n",
    "        x = K.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return K.mean(x)\n",
    "\n",
    "def my_func(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg\n",
    "\n",
    "def dice_loss_weighted(y_true, y_pred):\n",
    "    \n",
    "    arg = my_func([dice_inner_0(y_true, y_pred),dice_inner_1(y_true, y_pred),dice_inner_2(y_true, y_pred),dice_inner_3(y_true, y_pred),dice_inner_4(y_true, y_pred)])\n",
    "    score = average(arg)\n",
    "    return  1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=5):\n",
    "    dice=0\n",
    "    for index in range(numLabels):\n",
    "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
    "    print(dice)\n",
    "    return 1+dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_multilabel_loss(y_true, y_pred, numLabels=3, class_weights = [0,1,2]):\n",
    "    dice=0\n",
    "    #sth = tf.Variable(np.empty((), dtype='float32'))\n",
    "    #sth = []\n",
    "    for index in range(numLabels):\n",
    "        dice = tf.unstack(dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index]))\n",
    "        #sth = tf.concat([sth,dice],axis=0)\n",
    "        #sth.append(dice)\n",
    "    weighted_dice = K.constant(sth) * K.constant(class_weights)\n",
    "    return K.constant(1 - np.mean(weighted_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.01,2,1,0.01,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score_loss(gt, pr, beta=1, class_weights=weights, class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # calculate score\n",
    "    tp = K.sum(gt * pr, axis=axes)\n",
    "    fp = K.sum(pr, axis=axes) - tp\n",
    "    fn = K.sum(gt, axis=axes) - tp\n",
    "\n",
    "    score = ((1 + beta ** 2) * tp + smooth) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_channels(x, indexes, **kwargs):\n",
    "    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n",
    "    backend = K\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        x = backend.permute_dimensions(x, (3, 0, 1, 2))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 2, 3, 0))\n",
    "    else:\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "        x = backend.gather(x, indexes)\n",
    "        x = backend.permute_dimensions(x, (1, 0, 2, 3))\n",
    "    return x\n",
    "\n",
    "def get_reduce_axes(per_image, **kwargs):\n",
    "    backend = K\n",
    "    axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    if not per_image:\n",
    "        axes.insert(0, 0)\n",
    "    return axes\n",
    "\n",
    "def gather_channels(*xs, indexes=None, **kwargs):\n",
    "    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n",
    "    if indexes is None:\n",
    "        return xs\n",
    "    elif isinstance(indexes, (int)):\n",
    "        indexes = [indexes]\n",
    "    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def average(x, per_image=False, class_weights=None, **kwargs):\n",
    "    backend = K\n",
    "    if per_image:\n",
    "        x = backend.mean(x, axis=0)\n",
    "    if class_weights is not None:\n",
    "        x = x * class_weights\n",
    "    return backend.mean(x)\n",
    "\n",
    "def round_if_needed(x, threshold, **kwargs):\n",
    "    backend = K\n",
    "    if threshold is not None:\n",
    "        x = backend.greater(x, threshold)\n",
    "        x = backend.cast(x, backend.floatx())\n",
    "    return x\n",
    "\n",
    "def iou_score_loss(gt, pr, class_weights=[0.1,1,1,1,1], class_indexes=None, smooth=smooth, per_image=False, threshold=None, **kwargs):\n",
    "    backend = K\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    print(score)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return 1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "loss = f_score_loss\n",
    "optim = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model():\n",
    "#     in1 = Input(shape=(IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3))\n",
    "\n",
    "#     conv1 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "#     conv1 = Dropout(0.5)(conv1)\n",
    "#     conv1 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "#     pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "#     conv2 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "#     conv2 = Dropout(0.5)(conv2)\n",
    "#     conv2 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "#     pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "#     conv3 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "#     conv3 = Dropout(0.5)(conv3)\n",
    "#     conv3 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "#     pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "#     conv4 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "#     conv4 = Dropout(0.5)(conv4)\n",
    "#     conv4 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "#     up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
    "#     conv5 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
    "#     conv5 = Dropout(0.5)(conv5)\n",
    "#     conv5 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "#     up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
    "#     conv6 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "#     conv6 = Dropout(0.5)(conv6)\n",
    "#     conv6 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "#     up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "#     conv7 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "#     conv7 = Dropout(0.5)(conv7)\n",
    "#     conv7 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "#     segmentation = Conv2D(5, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "\n",
    "#     model = Model(inputs=[in1], outputs=[segmentation])\n",
    "    \n",
    "#     model.compile(optim, loss, metrics_test5)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    # drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    # drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(5, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs = [inputs], outputs = [conv10])\n",
    "     #model = Model(inputs=[in1], outputs=[segmentation])\n",
    "\n",
    "    model.compile(optim, loss=loss, metrics = metrics_test5)\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# with tf.device('/CPU:0'):\n",
    "\n",
    "train_dataset = Dataset(images_train, labels_train, classes=CLASSES)\n",
    "valid_dataset = Dataset(images_val, labels_val, classes=CLASSES)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# check shapes for errors\n",
    "assert train_dataloader[0][0].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3)\n",
    "assert train_dataloader[0][1].shape == (BATCH_SIZE, IMG_HEIGHT_UNET, IMG_WIDTH_UNET, n_classes)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    \n",
    "#     def on_train_batch_begin(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "#     def on_train_batch_end(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "#         res_dir = os.path.join(\"..\",\"data\",\"test_images\")\n",
    "    \n",
    "#         x_img = os.path.join(res_dir,\"X_input.jpg\")\n",
    "#         y_img = os.path.join(res_dir,\"Y_truth.jpg\")\n",
    "#         predicted_img = os.path.join(res_dir,f\"{epoch}_Y_predicted.jpg\")\n",
    "        \n",
    "#         image, gt_mask = train_dataset[100]\n",
    "#         #image = np.expand_dims(image, axis=0)\n",
    "#         pr_mask = self.model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "#         gt_mask_vis = gt_mask[...,0:3]\n",
    "#         pr_mask_vis = pr_mask[...,0:3]\n",
    "\n",
    "# #         visualize(\n",
    "# #             image=denormalize(image.squeeze()),\n",
    "# #             gt_mask_vis=gt_mask_vis.squeeze(),\n",
    "# #             pr_mask_vis=pr_mask_vis.squeeze(),\n",
    "# #         )\n",
    "\n",
    "#         cv2.imwrite(x_img, image[:,:,0])\n",
    "#         cv2.imwrite(y_img, gt_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, pr_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, prediction[0,:,:,:] * 255.)\n",
    "        \n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "        \n",
    "# pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_0211/cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "STEPS_PER_EPOCH = train_stop / BATCH_SIZE\n",
    "SAVE_PERIOD = 5\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH)\n",
    "    )\n",
    "\n",
    "# history_callback = tf.keras.callbacks.CSVLogger('history.csv',separator=',',append=False)\n",
    "\n",
    "# callbacks = [pb, cp_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = valid_dataset[100]\n",
    "visualize(\n",
    "    image=image[:,:,0], ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    no_tumor=mask[..., 0].squeeze(),\n",
    "    one=mask[..., 1].squeeze(),\n",
    "    two=mask[..., 2].squeeze(),\n",
    "    three=mask[..., 3].squeeze(),\n",
    "    four=mask[..., 4].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mask[...].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    validation_data=valid_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solutions to RAM memory problem\n",
    "\n",
    "    def __del__(self):\n",
    "        #put termination message\n",
    "        for i in range(self._workers)\n",
    "            self._notificationQueue.put(\"terminate\")\n",
    "        #empty queues, otherwise the workers won't terminate\n",
    "        for i in range(self._max_queue_size):\n",
    "            self._batchQueue.get(timeout=10)\n",
    "            \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for activation of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "\n",
    "\n",
    "def getActivations(layer,stimuli):\n",
    "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
    "    plotNNFilter(units)\n",
    "    \n",
    "    \n",
    "def plotNNFilter(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageToUse = image[:,:,0]\n",
    "plt.imshow(np.reshape(imageToUse,[256,256]), interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"unet_brats.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(checkpoint_path)\n",
    "# Restore the weights\n",
    "checkpoint_path = os.path.join('..', 'data', 'checkpoints')\n",
    "checkpoint_number = 'cp-0040.ckpt'\n",
    "checkpoint_path = os.path.join(checkpoint_path, checkpoint_number)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_mask = train_dataset[100]\n",
    "model.evaluate(image[np.newaxis, ...], gt_mask[np.newaxis, ...], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "# plt.figure(figsize=(30, 5))\n",
    "# plt.subplot(121)\n",
    "# plt.plot(history.history['f1-score'])\n",
    "# plt.plot(history.history['val_f1-score'])\n",
    "# plt.title('Model f1-score')\n",
    "# plt.ylabel('f1-score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylim([0,1])\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [80]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,4].squeeze(),\n",
    "        pr_mask=pr_mask[...,4].squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_mappings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(pr_mask[0,:,:,1], cmap = colour_mappings[i],alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr_mask[0,:,:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_feat_dir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\")\n",
    "img_feat = nib.load(test_img_feat_dir)\n",
    "imgarr_feat = img_feat.get_fdata()\n",
    "test_img_feat_slice = imgarr_feat[:,:,100]\n",
    "test_img = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "test_img[:,:,0] = test_img_feat_slice\n",
    "test_img[:,:,1] = test_img_feat_slice\n",
    "test_img[:,:,2] = test_img_feat_slice\n",
    "\n",
    "plt.imshow(test_img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_predicted_3 = os.path.join(\"..\",\"data\",\"test_images\",\"3_Y_predicted.jpg\")\n",
    "directory_predicted_29 = os.path.join(\"..\",\"data\",\"test_images\",\"29_Y_predicted.jpg\")\n",
    "directory_predicted_39 = os.path.join(\"..\",\"data\",\"test_images\",\"20_Y_predicted.jpg\")\n",
    "directory_predicted_49 = os.path.join(\"..\",\"data\",\"test_images\",\"31_Y_predicted.jpg\")\n",
    "directory_y = os.path.join(\"..\",\"data\",\"test_images\",\"Y_truth.jpg\")\n",
    "directory_X = os.path.join(\"..\",\"data\",\"test_images\",\"X_input.jpg\")\n",
    "\n",
    "visualize(\n",
    "    input_image=cv2.imread(directory_X,0).squeeze(),\n",
    "    ground_truth=cv2.imread(directory_y,0).squeeze(),\n",
    "    predicted_3=cv2.imread(directory_predicted_3,0),\n",
    "    predicted_29=cv2.imread(directory_predicted_29,0),\n",
    "    predicted_39=cv2.imread(directory_predicted_39,0),\n",
    "    predicted_49=cv2.imread(directory_predicted_49,0),### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
