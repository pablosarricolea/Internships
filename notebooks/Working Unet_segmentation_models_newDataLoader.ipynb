{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "good paper about losses:\n",
    "https://arxiv.org/pdf/2006.14822.pdf\n",
    "\n",
    "try freezing the encoder?? what does it mean? --> https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "transfer learning in encoder with tumor relared neural network\n",
    "how to implement dropout\n",
    "number of parameters in network\n",
    "resnet34 or densenet121\n",
    "\n",
    "TODOs:\n",
    "\n",
    "check the activation of layers --> https://awjuliani.medium.com/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4\n",
    "implement shuffling in the generator --> https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb // https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow import keras\n",
    "# import segmentation_models as sm\n",
    "\n",
    "# def get_model_with_dropout(base_model_name='efficientnetb4',activation='sigmoid',dropout = 0.1):\n",
    "#     base_model = sm.Unet(base_model_name, encoder_weights='imagenet')\n",
    "#     base_model_input = base_model.input\n",
    "#     base_model_output = base_model.get_layer('final_conv').output\n",
    "#     #add dropout\n",
    "#     base_model_output = keras.layers.Dropout(dropout)(base_model_output)\n",
    "#     #add activation\n",
    "#     output = keras.layers.Activation(activation, name=activation)(base_model_output)\n",
    "#     model_dp = keras.models.Model(base_model_input, output)\n",
    "\n",
    "#     return model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-259baabeb65a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgpu6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_available_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-259baabeb65a>\u001b[0m in \u001b[0;36mget_available_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_available_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlocal_device_protos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_device_protos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvironment/project_2/lib/python3.6/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mserialized_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   return [\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pywrap_device_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "#Run from server\n",
    "\n",
    "gpu4 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu7 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu6\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "IMG_DEPTH = 155\n",
    "\n",
    "IMG_HEIGHT_UNET = 256\n",
    "IMG_WIDTH_UNET = 256\n",
    "\n",
    "N_IMG = 369\n",
    "length_file = IMG_DEPTH * N_IMG\n",
    "h5py_file_name = 'delete.hdf5'\n",
    "# h5py_file_name = 'brats2020_full_normalized.hdf5'\n",
    "smooth = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the data and creating data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path_directory, h5py_file_directory):\n",
    "    \n",
    "    def path_extraction(path_directory):\n",
    "    \n",
    "        ImgDir = path_directory\n",
    "        features_t1_path = []\n",
    "        features_t1ce_path = []\n",
    "        features_t2_path = []\n",
    "        features_flair_path = []\n",
    "        labels_path = []\n",
    "        count = 0\n",
    "\n",
    "        for folder in os.listdir(ImgDir):\n",
    "            count +=1\n",
    "            if 'Training' in folder:\n",
    "                new_dir = os.path.join(ImgDir,folder)\n",
    "                data = os.listdir(new_dir)\n",
    "                for files in data:\n",
    "                    if 't1' in files:\n",
    "                        features_t1_path.append(os.path.join(new_dir, files))\n",
    "                    if 't1ce' in files:\n",
    "                        features_t1ce_path.append(os.path.join(new_dir, files))\n",
    "                    if 't2' in files:\n",
    "                        features_t2_path.append(os.path.join(new_dir, files))\n",
    "                    if 'flair' in files:\n",
    "                        features_flair_path.append(os.path.join(new_dir, files))\n",
    "                    if 'seg' in files:\n",
    "                        labels_path.append(os.path.join(new_dir, files))\n",
    "\n",
    "        #print(len(features_path))\n",
    "        #print(len(labels_path))\n",
    "        \n",
    "        return features_t1_path, features_t1ce_path, features_t2_path, features_flair_path, labels_path\n",
    "    \n",
    "    def concatenate_images(path, features = None):\n",
    "        \n",
    "        IMG_HEIGHT = 240\n",
    "        IMG_WIDTH = 240\n",
    "        IMG_DEPTH = 155\n",
    "        \n",
    "        img_conc = np.zeros((len(path),IMG_HEIGHT,IMG_WIDTH,IMG_DEPTH))\n",
    "\n",
    "        for file, i in zip(path,range(len(path))):\n",
    "            img = nib.load(file)\n",
    "            imgarr = img.get_fdata()\n",
    "            \n",
    "            if features:\n",
    "                \n",
    "#                 mean = np.mean(imgarr)\n",
    "#                 std = np.std(imgarr)\n",
    "#                 imgarr_norm = (imgarr - mean) / std\n",
    "#                 imgarr_norm_clip = np.clip(imgarr_norm,-5,5)\n",
    "#                 imgarr_std = imgarr_norm_clip/np.max(imgarr_norm_clip)\n",
    "#                 imgarr = imgarr_std\n",
    "                \n",
    "                scaler = MinMaxScaler()\n",
    "                imgarr_fit = scaler.fit_transform(imgarr)\n",
    "            \n",
    "            img_conc[i,:,:,:] = imgarr_fit\n",
    "            plt.imshow(imgarr_fit[...,75])\n",
    "            print(\"min: \", np.min(imgarr_fit, \" max: \", np.nax(imgarr_fit)))\n",
    "\n",
    "        img_conc = np.concatenate(img_conc,axis=2)\n",
    "        print(np.shape(img_conc_features))\n",
    "        \n",
    "        return img_conc\n",
    "    \n",
    "    def create_h5py(img_conc_features_t1, img_conc_features_t1ce, img_conc_features_t2, img_conc_features_flair, img_conc_labels, h5py_file_directory):\n",
    "        \n",
    "        with h5py.File(h5py_file_directory, 'a') as f:\n",
    "            f.create_dataset(\"t1\", data=img_conc_features_t1, compression=\"gzip\")\n",
    "            f.create_dataset(\"t1ce\", data=img_conc_features_t1ce, compression=\"gzip\")\n",
    "            f.create_dataset(\"t2\", data=img_conc_features_t2, compression=\"gzip\")\n",
    "            f.create_dataset(\"flair\", data=img_conc_features_flair, compression=\"gzip\")\n",
    "            f.create_dataset(\"labels\", data=img_conc_labels, compression=\"gzip\")\n",
    "            \n",
    "    features_t1_path, features_t1ce_path, features_t2_path, features_flair_path, labels_path = path_extraction(path_directory)\n",
    "    \n",
    "    img_conc_features_t1 = concatenate_images(features_t1_path, features = True)\n",
    "    img_conc_features_t1ce = concatenate_images(features_t1ce_path, features = True)\n",
    "    img_conc_features_t2 = concatenate_images(features_t2_path, features = True)\n",
    "    img_conc_features_flair = concatenate_images(features_flair_path, features = True)\n",
    "    img_conc_labels = concatenate_images(labels_path, features = False)\n",
    "    \n",
    "    create_h5py(img_conc_features_t1, img_conc_features_t1ce, img_conc_features_t2, img_conc_features_flair, img_conc_labels, h5py_file_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "# dataset_directory = os.path.join(\"..\",\"data\",\"can_be_deleted.hdf5\")\n",
    "\n",
    "path_directory = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "dataset_directory = os.path.join(\"..\",\"data\", h5py_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset(path_directory,dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"features\"][:, :, 100]\n",
    "\n",
    "print(np.min(test_img))\n",
    "    \n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_store_Brats = h5py.File(os.path.join('..','data',h5py_file_name), \"r\")\n",
    "test_img = hdf5_store_Brats[\"labels\"][:, :, 100]\n",
    "plt.imshow(test_img, cmap ='gray')\n",
    "hdf5_store_Brats.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "\n",
    "BACKBONE = 'resnet34' #'densenet121' \n",
    "CLASSES = ['0','1','2','3','4']\n",
    "LR = 0.0001\n",
    "EPOCHS = 70\n",
    "n_classes = 5\n",
    "BATCH_SIZE = 32\n",
    "#decoder_filters = (128, 64, 32, 16, 8)   #standard:(256, 128, 64, 32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "def visualize_histories(**images):\n",
    "    \"\"\"Import as tuples: one = (a,b)\"\"\"\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('epoch')\n",
    "        if i == 0:\n",
    "            plt.ylabel('dice_score')\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.plot(np.asarray(image[0]))\n",
    "        plt.plot(np.asarray(image[1]))\n",
    "        plt.legend(['train', 'val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "\n",
    "class SingleDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=2, dim=(240,240), dim_unet=(256,256), n_channels=3,\n",
    "                 n_classes=5, classes = CLASSES, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.dim_unet = dim_unet\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.classes = classes\n",
    "        self.class_values = [self.classes.index(cls.lower()) for cls in self.classes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        X, y1 = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        # X = np.zeros((self.batch_size, *self.dim_unet, self.n_channels))\n",
    "        # y1 = np.zeros((self.batch_size, *self.dim_unet, self.n_classes))\n",
    "        \n",
    "#         for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "\n",
    "        with h5py.File(os.path.join('..','data',h5py_file_name), \"r\") as f:\n",
    "            #images_train = f[\"features\"][()] #the whole dataset: 57195 images\n",
    "            #labels_train = f[\"labels\"][()]\n",
    "\n",
    "            images = f[\"features\"]\n",
    "            labels = f[\"labels\"]\n",
    "\n",
    "            X_temp = np.zeros((self.batch_size, *self.dim_unet, self.n_channels))\n",
    "            y_temp = np.zeros((self.batch_size, *self.dim_unet))\n",
    "\n",
    "            X_temp[:,:IMG_HEIGHT,:IMG_WIDTH,0] = tf.transpose(tf.constant(images[:,:,list_IDs_temp],dtype=tf.float32),[2,0,1])\n",
    "            X_temp[:,:IMG_HEIGHT,:IMG_WIDTH,1] = X_temp[:,:IMG_HEIGHT,:IMG_WIDTH,0]\n",
    "            X_temp[:,:IMG_HEIGHT,:IMG_WIDTH,2] = X_temp[:,:IMG_HEIGHT,:IMG_WIDTH,0]\n",
    "\n",
    "            X_temp = tf.transpose(X_temp, [2, 0, 1, 3])\n",
    "\n",
    "            \n",
    "            y_temp[:,:IMG_HEIGHT,:IMG_WIDTH] = tf.transpose(tf.constant(labels[:,:,list_IDs_temp],dtype=tf.float32),[2, 0, 1])\n",
    "            y_temp = tf.transpose(y_temp, [2, 0, 1])\n",
    "\n",
    "            # extract certain classes from mask (e.g. cars)\n",
    "            masks = [(y_temp == v) for v in self.class_values]\n",
    "            y_temp = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        return X_temp, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES))  # case for binary and multiclass segmentation\n",
    "# n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "#encoder weights from ImageNet, not pretty realted to tumors, so i delete it, interesting to add other weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates dice considering an input with a single class\n",
    "def dice_single(true,pred):\n",
    "    true = K.batch_flatten(true)\n",
    "    pred = K.batch_flatten(pred)\n",
    "    pred = K.round(pred)\n",
    "\n",
    "    intersection = K.sum(true * pred, axis=-1)\n",
    "    true = K.sum(true, axis=-1)\n",
    "    pred = K.sum(pred, axis=-1)\n",
    "\n",
    "    return ((2*intersection) + K.epsilon()) / (true + pred + K.epsilon())\n",
    "\n",
    "def dice_inner_0(true,pred,index=0):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_1(true,pred,index=1):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_2(true,pred,index=2):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_3(true,pred,index=3):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "def dice_inner_4(true,pred,index=4):\n",
    "\n",
    "    #get only the desired class\n",
    "    true = true[:,:,:,index]\n",
    "    pred = pred[:,:,:,index]\n",
    "\n",
    "    #return dice per class\n",
    "    return dice_single(true,pred)\n",
    "\n",
    "metrics_test5 = [dice_inner_0, dice_inner_1, dice_inner_2, dice_inner_3, dice_inner_4, sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "total_loss = sm.losses.DiceLoss(class_weights=np.array([0.1, 1, 1, 0.1, 1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stop = 9001\n",
    "valid_stop = 10000\n",
    "\n",
    "params = {'dim_unet': (256,256),\n",
    "          'batch_size': 32,\n",
    "          'n_classes': 5,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False}\n",
    "\n",
    "train_generator = SingleDataGenerator(range(train_stop),**params)\n",
    "valid_generator = SingleDataGenerator(np.arange(train_stop,valid_stop),**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = os.path.join(\"..\",\"data\",\"test_images_1\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "    \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        \n",
    "#         res_dir = os.path.join(\"..\",\"data\",\"test_images_segmentation_models\")\n",
    "    \n",
    "#         x_img = os.path.join(res_dir,\"X_input.jpg\")\n",
    "#         y_img = os.path.join(res_dir,\"Y_truth.jpg\")\n",
    "#         predicted_img = os.path.join(res_dir,f\"{epoch}_Y_predicted.jpg\")\n",
    "        \n",
    "#         image, gt_mask = train_dataset[100]\n",
    "#         #image = np.expand_dims(image, axis=0)\n",
    "#         pr_mask = self.model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "#         gt_mask_vis = gt_mask[...,0:3]\n",
    "#         pr_mask_vis = pr_mask[...,0:3]\n",
    "\n",
    "#         cv2.imwrite(x_img, image[:,:,0])\n",
    "#         cv2.imwrite(y_img, gt_mask_vis.squeeze())\n",
    "#         cv2.imwrite(predicted_img, pr_mask_vis.squeeze())\n",
    "        \n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "pb = printbatch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path =  os.path.join(\"..\",\"data\",\"checkpoints\",\"training_segmentation_models/cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "STEPS_PER_EPOCH = train_stop / BATCH_SIZE\n",
    "SAVE_PERIOD = 5\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH)\n",
    "    )\n",
    "\n",
    "history_callback = tf.keras.callbacks.CSVLogger('history_segmentation_models.csv',separator=',',append=False)\n",
    "\n",
    "callbacks = [pb, cp_callback, history_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_histories(\n",
    "    class_zero = (history.history['dice_inner_0'], history.history['val_dice_inner_0']), ### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    class_one = (history.history['dice_inner_1'], history.history['val_dice_inner_1']),\n",
    "    class_two = (history.history['dice_inner_2'], history.history['val_dice_inner_2']),\n",
    "    class_three = (history.history['dice_inner_3'], history.history['val_dice_inner_3']),\n",
    "    class_four = (history.history['dice_inner_4'], history.history['val_dice_inner_4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= os.path.join(\"..\",\"data\",\"checkpoints\",\"unet_brats.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path)\n",
    "# Restore the weights\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['f1-score'])\n",
    "plt.plot(history.history['val_f1-score'])\n",
    "plt.title('Model f1-score')\n",
    "plt.ylabel('f1-score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "# ids = np.random.choice(np.arange(len(labels_train)), size=n)\n",
    "ids = [50]\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = valid_dataset[i]\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[...,1:4].squeeze(),\n",
    "        pr_mask=pr_mask[...,0:3].squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = sm.Unet('resnet34', classes = 5, input_shape=(IMG_HEIGHT_UNET, IMG_WIDTH_UNET, 3))\n",
    "# model.compile(\n",
    "#     'Adam',\n",
    "#     loss=sm.losses.bce_jaccard_loss,\n",
    "#     metrics=[sm.metrics.iou_score],\n",
    "# )\n",
    "# history = model.fit_generator(train_dataloader, epochs = 20, verbose=1, validation_data=None, class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image visualization of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_feat_dir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\")\n",
    "img_feat = nib.load(test_img_feat_dir)\n",
    "imgarr_feat = img_feat.get_fdata()\n",
    "test_img_feat_slice = imgarr_feat[:,:,100]\n",
    "test_img = np.zeros((240, 240 ,3), np.float32)\n",
    "\n",
    "test_img[:,:,0] = test_img_feat_slice\n",
    "test_img[:,:,1] = test_img_feat_slice\n",
    "test_img[:,:,2] = test_img_feat_slice\n",
    "\n",
    "plt.imshow(test_img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_predicted_3 = os.path.join(\"..\",\"data\",\"test_images_1\",\"3_Y_predicted.jpg\")\n",
    "directory_predicted_29 = os.path.join(\"..\",\"data\",\"test_images\",\"29_Y_predicted.jpg\")\n",
    "directory_predicted_39 = os.path.join(\"..\",\"data\",\"test_images\",\"39_Y_predicted.jpg\")\n",
    "directory_predicted_49 = os.path.join(\"..\",\"data\",\"test_images\",\"49_Y_predicted.jpg\")\n",
    "directory_y = os.path.join(\"..\",\"data\",\"test_images\",\"Y_truth.jpg\")\n",
    "directory_X = os.path.join(\"..\",\"data\",\"test_images\",\"X_input.jpg\")\n",
    "\n",
    "visualize(\n",
    "    input_image=cv2.imread(directory_X,0).squeeze(),\n",
    "    ground_truth=cv2.imread(directory_y,0).squeeze(),\n",
    "    predicted_3=cv2.imread(directory_predicted_3,0),\n",
    "    predicted_29=cv2.imread(directory_predicted_29,0),\n",
    "    predicted_39=cv2.imread(directory_predicted_39,0),\n",
    "    predicted_49=cv2.imread(directory_predicted_39,0),### if putting the whole image, black and white, could it be the reason of the problem??\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
