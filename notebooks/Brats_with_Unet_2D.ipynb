{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "See the predictions\n",
    "Improve the dataset generator\n",
    "Create a numpy file for saving the vbles\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1607558031996,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "ncjggBBMM8Q6"
   },
   "outputs": [],
   "source": [
    "#Run from server\n",
    "\n",
    "gpu4 = \"GPU-71b4cdfc-e381-0b98-9b24-4fc06284b496\" \n",
    "gpu5 = \"GPU-99d0769a-9f86-4800-a40e-2320dddcf5d1\" \n",
    "gpu6 = \"GPU-7423cfb5-cff4-ec4d-7e96-ea6e1591d56f\"\n",
    "gpu7 = \"GPU-c0a8738f-6dd0-1b78-c38f-4969fd3886a8\"\n",
    "\n",
    "import os\n",
    "#\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu6 + \",\" + gpu5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34726,
     "status": "ok",
     "timestamp": 1607558066128,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "6Wd25fj01M7m",
    "outputId": "c6741e13-7d7b-4ddc-e70a-fd86eeb9c918"
   },
   "outputs": [],
   "source": [
    "#Run from google colab\n",
    "\n",
    "!pip install SimpleITK\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35105,
     "status": "ok",
     "timestamp": 1607558066514,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "EqJdeezG6fLH",
    "outputId": "a97c460b-21a3-455d-e4cf-a5457654cc07"
   },
   "outputs": [],
   "source": [
    "%cd /content/gdrive/MyDrive/2 TUM/Project/Internships/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38609,
     "status": "ok",
     "timestamp": 1607558070023,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "BjUoBkLpM8RI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38606,
     "status": "ok",
     "timestamp": 1607558070023,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "MNqOa1hrM8RJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44810,
     "status": "ok",
     "timestamp": 1607558076233,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "bY-nywdUM8RK"
   },
   "outputs": [],
   "source": [
    "img_t1 = sitk.ReadImage(os.path.join(\"..\", \"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_t1.nii.gz\"))\n",
    "img_t1ce = sitk.ReadImage(os.path.join(\"..\", \"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_t1ce.nii.gz\"))\n",
    "img_t2 = sitk.ReadImage(os.path.join(\"..\", \"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_t2.nii.gz\"))\n",
    "img_flair = sitk.ReadImage(os.path.join(\"..\", \"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_flair.nii.gz\"))\n",
    "img_seg = sitk.ReadImage(os.path.join(\"..\", \"data\",\"MICCAI_BraTS2020_TrainingData\",\"BraTS20_Training_001\",\"BraTS20_Training_001_seg.nii.gz\"))\n",
    "\n",
    "\"\"\"\n",
    "img_t1 = sitk.Cast(img_t1,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_t1ce = sitk.Cast(img_t1ce,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_t2 = sitk.Cast(img,sitk_t2.sitkFloat32) #to ceonvert png to sitk\n",
    "img_flair = sitk.Cast(img_flair,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "img_seg = sitk.Cast(img_seg,sitk.sitkFloat32) #to ceonvert png to sitk\n",
    "\n",
    "print(img.GetSize())\n",
    "print(img.GetOrigin()) # the top left corner usually\n",
    "print(img.GetSpacing()) #physical size of each pixel\n",
    "print(img.GetDirection()) #3D matrix\n",
    "print(img.GetNumberOfComponentsPerPixel()) #number of channels in one pixel\n",
    "\"\"\"\n",
    "\n",
    "width = img_t1.GetWidth()\n",
    "height = img_t1.GetHeight()\n",
    "depth = img_t1.GetDepth()\n",
    "\n",
    "nda_t1 = sitk.GetArrayViewFromImage(img_t1)\n",
    "nda_t1ce = sitk.GetArrayViewFromImage(img_t1ce)\n",
    "nda_t2 = sitk.GetArrayViewFromImage(img_t2)\n",
    "nda_flair = sitk.GetArrayViewFromImage(img_flair)\n",
    "nda_seg = sitk.GetArrayViewFromImage(img_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 45373,
     "status": "ok",
     "timestamp": 1607558076801,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "Wx_XucrQM8RK",
    "outputId": "1cc1770a-0265-4393-fb6c-b1141aa850e2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npa_zslice_t1 = sitk.GetArrayViewFromImage(img_t1)[int(depth/2),:,:]\n",
    "npa_zslice_t1ce = sitk.GetArrayViewFromImage(img_t1ce)[int(depth/2),:,:]\n",
    "npa_zslice_t2 = sitk.GetArrayViewFromImage(img_t2)[int(depth/2),:,:]\n",
    "npa_zslice_flair = sitk.GetArrayViewFromImage(img_flair)[int(depth/2),:,:]\n",
    "npa_zslice_seg = sitk.GetArrayViewFromImage(img_seg)[int(depth/2),:,:]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "fig.add_subplot(1,5,1)\n",
    "plt.imshow(npa_zslice_t1, cmap=plt.cm.Greys_r)\n",
    "plt.title('T1', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,2)\n",
    "plt.imshow(npa_zslice_t1ce, cmap=plt.cm.Greys_r)\n",
    "plt.title('T1_ce', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,3)\n",
    "plt.imshow(npa_zslice_t2, cmap=plt.cm.Greys_r)\n",
    "plt.title('T2', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,4)\n",
    "plt.imshow(npa_zslice_flair, cmap=plt.cm.Greys_r)\n",
    "plt.title('flair', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "fig.add_subplot(1,5,5)\n",
    "plt.imshow(npa_zslice_seg, cmap=plt.cm.Greys_r)\n",
    "plt.title('Segmentation', fontsize=10)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67347,
     "status": "ok",
     "timestamp": 1607558098781,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "sO-rakilM8RL",
    "outputId": "efa67ef7-06b8-4f58-a83f-af84e612a2d9"
   },
   "outputs": [],
   "source": [
    "ImgDir = os.path.join(\"..\",\"data\",\"MICCAI_BraTS2020_TrainingData\")\n",
    "features_path = list()\n",
    "labels_path = list()\n",
    "count = 0\n",
    "lim = 100\n",
    "\n",
    "for folder in os.listdir(ImgDir):\n",
    "    count +=1\n",
    "    if 'Training' in folder and count<lim:\n",
    "        new_dir = os.path.join(ImgDir,folder)\n",
    "        data = os.listdir(new_dir)\n",
    "        for files in data:\n",
    "            if 'flair' in files:\n",
    "                features_path.append(os.path.join(new_dir, files))\n",
    "            if 'seg' in files:\n",
    "                labels_path.append(os.path.join(new_dir, files))\n",
    "\n",
    "print(len(features_path))\n",
    "print(len(labels_path))\n",
    "\n",
    "X=features_path\n",
    "Y=labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = tf.data.Dataset.list_files(features_path)\n",
    "dataset_labels = tf.data.Dataset.list_files(labels_path)\n",
    "\n",
    "dcombined = tf.data.Dataset.zip((dataset_features, dataset_labels))\n",
    "\n",
    "dataset = dcombined.cache()\n",
    "# The first time reading through the data will generate the data using\n",
    "# `range` and `map`.\n",
    "print(dataset_features)\n",
    "print(list(dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the iterator\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 67344,
     "status": "ok",
     "timestamp": 1607558098783,
     "user": {
      "displayName": "PABLO SARRICOLEA VALENCIANO",
      "photoUrl": "",
      "userId": "03055843788957929628"
     },
     "user_tz": -60
    },
    "id": "gDRuLlbeM8RN"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator_train_val_test(batch_size, choice=\"train\"):\n",
    "\n",
    "    if choice == \"train\":\n",
    "        X = X_train\n",
    "        Y = y_train\n",
    "    elif choice == \"val\":\n",
    "        X = X_val\n",
    "        y = y_val\n",
    "    else:\n",
    "        print(\"Invalid Option\")\n",
    "        return False\n",
    "    \n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            rand = random.choice(range(len(X)))\n",
    "\n",
    "            x_path = X[rand]\n",
    "            y_path = Y[rand]\n",
    "\n",
    "            x = sitk.GetArrayViewFromImage(sitk.ReadImage(x_path)) / 255.\n",
    "            y = sitk.GetArrayViewFromImage(sitk.ReadImage(y_path)) / 255.\n",
    "            \n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "\n",
    "        x_batch = np.concatenate(np.array(x_batch),0)\n",
    "        y_batch = np.concatenate(np.array(y_batch),0)\n",
    "        \n",
    "        x_batch, y_batch = shuffle(x_batch, y_batch)\n",
    "\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in keras_generator_train_val_test(1, choice=\"train\"):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sizeof = sys.getsizeof(x_data)\n",
    "print(sizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "class MY_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.image_filenames) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "class BRATSSequence(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = X, Y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        \n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            rand = random.choice(range(len(X)))\n",
    "\n",
    "            \n",
    "            #y si cojo batch_x????\n",
    "            x_path = self.x[rand]\n",
    "            y_path = self.y[rand]\n",
    "            \n",
    "            x = sitk.GetArrayViewFromImage(sitk.ReadImage(x_path)) / 255.\n",
    "            y = sitk.GetArrayViewFromImage(sitk.ReadImage(y_path)) / 255.\n",
    "            \n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            \n",
    "        x_batch = np.concatenate(np.array(x_batch),0)\n",
    "        y_batch = np.concatenate(np.array(y_batch),0)\n",
    "        \n",
    "        x_batch, y_batch = shuffle(x_batch, y_batch)\n",
    "\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "sequence = BRATSSequence(X, Y, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, mask_path,\n",
    "                 to_fit=True, batch_size=32, dim=(240, 240),\n",
    "                 n_channels=1, n_classes=4, shuffle=True):\n",
    "        \"\"\"Initialization\n",
    "\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator\n",
    "        :param labels: list of image labels (file names)\n",
    "        :param image_path: path to images location\n",
    "        :param mask_path: path to masks location\n",
    "        :param to_fit: True to return X and y, False to return X only\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param dim: tuple indicating image dimension\n",
    "        :param n_channels: number of image channels\n",
    "        :param n_classes: number of output masks\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "    \n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.image_path) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [k for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(list_IDs_temp)\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(list_IDs_temp)\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    #def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "\n",
    "        \"\"\"\n",
    "    #    self.indexes = np.arange(len(self.list_IDs))\n",
    "    #    if self.shuffle == True:\n",
    "    #        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.image_path))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_X(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate (list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = self._image_transformation(self.image_path[ID])\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _generate_y(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size masks\n",
    "\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch if masks\n",
    "        \"\"\"\n",
    "        y = np.empty((self.batch_size, *self.dim), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            y[i,] = self._image_transformation(self.mask_path[ID])\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _image_transformation(self, image_path):\n",
    "        \"\"\"Load grayscale image\n",
    "\n",
    "        :param image_path: path to image to load\n",
    "        :return: loaded image\n",
    "        \"\"\"\n",
    "        img = sitk.GetArrayViewFromImage(sitk.ReadImage(image_path)) / 255.\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingGenerator = DataGenerator(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 240\n",
    "smooth = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def get_model():\n",
    "    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1 ))\n",
    "\n",
    "    conv1 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv1 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "    conv4 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    conv5 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    conv6 = Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    conv7 = Conv2D(4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    segmentation = Conv2D(1, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[segmentation])   \n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2=get_model()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tup = (X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=os.path.join(\"..\",\"data\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(trainingGenerator, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSz_UubJjP2W"
   },
   "outputs": [],
   "source": [
    "model2.fit(X_train, y_train, batch_size = 32, validation_data =validation_tup, epochs=20, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=logdir --port=6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-BeUkyKM8RR"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "\n",
    "        res_dir = \"intermediate_results_black_background\"\n",
    "\n",
    "        try:\n",
    "            os.makedirs(res_dir)\n",
    "        except:\n",
    "            print(f\"{res_dir} directory already exist\")\n",
    "\n",
    "        print('Training: epoch {} begins at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        res_dir = \"intermediate_results_black_background/\"\n",
    "        print('Training: epoch {} ends at {}'.format(epoch, datetime.datetime.now().time()))\n",
    "        \n",
    "        for x_test, y_test in keras_generator_train_val_test(batch_size, choice=\"test\"):\n",
    "            break\n",
    "        p = np.reshape(x_test[0], (1, 512, 512, 3))\n",
    "        prediction = self.model.predict(p)\n",
    "\n",
    "        x_img = f\"{res_dir}{epoch}_X_input.jpg\"\n",
    "        y_img = f\"{res_dir}{epoch}_Y_truth.jpg\"\n",
    "        predicted_img = f\"{res_dir}{epoch}_Y_predicted.jpg\"\n",
    "\n",
    "        cv2.imwrite(x_img, x_test[0] * 255.)\n",
    "        cv2.imwrite(y_img, y_test['seg'][0] * 255.)\n",
    "        cv2.imwrite(predicted_img, prediction[0] * 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W7zyRVeM8RT"
   },
   "outputs": [],
   "source": [
    "model_name = \"..\\\\data\\\\Unet_black_background_47_epochs.h5\"\n",
    "\n",
    "batch_size = 2;\n",
    "\n",
    "#modelcheckpoint = ModelCheckpoint(model_name,\n",
    "                                  monitor='val_loss',\n",
    "                                  mode='auto',\n",
    "                                  verbose=1,\n",
    "#                                  save_best_only=True)\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
    "\n",
    "#callback_list = [modelcheckpoint, lr_callback, MyCustomCallback()]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    keras_generator_train_val_test(batch_size, choice=\"train\"),\n",
    "    validation_data = keras_generator_train_val_test(batch_size, choice=\"val\"),\n",
    "    validation_steps = 100,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=epochs,\n",
    "    verbose=1, \n",
    "    shuffle=True\n",
    "    #callbacks = callback_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjzS92XpM8RT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnknhEgvM8RT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ps25gWvlM8RT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d11KGAPuM8RU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH1AqM94M8RU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxR32i1gM8RU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZcnijZTM8RU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JL_jjkKHM8RU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Brats_with_Unet.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pablosarricolea/Internships/blob/main/notebooks/Brats_with_Unet.ipynb",
     "timestamp": 1607556725258
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
